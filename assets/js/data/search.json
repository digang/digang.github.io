 [ { "title": "[리눅스] Linux 작업 예약 스케줄러 (크론 cron) ", "url": "/posts/%EB%A6%AC%EB%88%85%EC%8A%A4-cron-%EC%9E%91%EC%97%85-%EC%98%88%EC%95%BD-%EB%AA%85%EB%A0%B9/", "categories": "리눅스, 명령어", "tags": "리눅스, linux", "date": "2022-08-14 00:00:00 +0900", "snippet": "Cron 이란?특정한 시간에 또는 특정 시간 마다 어떤 작업을 자동으로 수행하게 해주고 싶을 때 사용하는 명령어가 cron이다.cron은 특정한 시간에 특정한 작업을 수항하게 해주는 스케줄링 역할을 한다.cron은 왜 사용할까?만약 당신이 회사에서 매 새벽 5시에 백업을 해야 한다면, 하루 이틀 정도라면 퇴근하지 않고 기다릴 수 있겠지만, 매일 한다면,, 또 심지어는 야근수당까지 나오지 않는다면? 이런 경우 주기적으로 반복되는 일을 자동으로 실행할 수 있도록 시스템 작업을 예약해줘야 한다.Crontab 과 cron과 관련된 몇 가지 파일들1. crontabcron작업을 설정하는 파일을 crontab파일이라 한다.cron 프로세스는 /etc/crontab 파일에 설정된 것을 읽어서 작업을 수행한다. crontab 파일은 OS별로 (ubuntu, centOS) 별로 각각 다른 위치에 저장 된다.기억하기분 - 시 - 일 - 월(month 기준) - 요일 - 사용자 - 실행명령2. cron /etc/cron.daily 와 /etc/cron.weekly 그리고 /etc/cron.monthly 파일이 존재하는데, 이 파일들은 시스템크론설정디렉토리다. 즉 시간, 일, 주, 월별로 파일을 저장한다. /var/log/cron : 크론 실행파일이 기록되는 로그파일 /etc/cron.allow, etc/cron.deny : 크론 접근을 허용할 ID, 크론 접근을 허용하지 않을 ID 등을 설정할 수 있다.Cron 동작 방식, cron 실행 흐름크론이 뭔지, 크론이 어떤 역할을 하는지, 관련파일은 뭐가 있는지 알아보면, cron이 어떻게 동작하는지 좀 더 자세히 알아보자. cron파일이 데몬이기 때문에 부팅시 백그라운드로 실행된다.crontab 설정형식과 cron 지정, 등록하기크론을 생성하기전에 크론탭 형식을 먼저 살펴보자.먼저 crontab 파일의 7필드m h dom mon dow user command m : 분(minute)을 나타내고, 0~59로 설정한다 h : 시(hour)을 나타내고 0~23으로 설정한다. dom : 날(day of month) 를 나타내고, 1-31로 설정한다. mon : 월(month)을 나타내고 1-12로 설정한다. dow : 요일(day of week)을 나타내고 0-7로 설정. 0과 7을 일요일에 해당한다. user : user-name 사용자 이름을 명시한다 command : 실행할 명령어를 기입한다. 명령어 앞에 사용자 이름을 명시해도 된다. $ crontab [option] 파일명사용자가 주기적인 작업을 등록하기 위해 사용하는 명령어유용한 cron 설정 예시1. 매일 2.am 에 백업하기 0 2 * * * /bin/sh backup.sh2. 하루에 두번 script.sh 수행 0 5, 17 * * * /scripts/script.sh3. 매분 수행 * * * * * /scripts/script.sh4. 매 10분마다 monitor 스크립트 실행 */10 * * * * /scripts/monitor.sh5. 1월부터 12월까지 2개월마다 1일날 오전 4시 10분에 /etc/check.sh 스크립트 수행 10 4 1 1-12/2 * /etc/check.sh 이 외에 더 많은 명령어는 구글에 검색만해도 많이 나온다." }, { "title": "[Python] - 코테 쓸만한 함수, 모듈 정리", "url": "/posts/python-counter/", "categories": "Python, 파이썬, module, collections", "tags": "백준, 알고리즘, 파이썬, python", "date": "2022-04-27 00:00:00 +0900", "snippet": "목록 Counter combinations permutations upper isalpha1. Counter Counter 는 Collections 모듈에 들어있는 클래스로써 다음과 같이 선언할 수 있다.from collections import Counter이때, Counter(대문자)임에 유의하도록 하자.다음은 Counter 의 함수들에 대해 알아보도록 하자.elements()import collectionsex_counter = collections.Counter(&quot;I want success&quot;)print(list(ex_counter.elements()))print(sorted(ex_counter.elements())) # 정렬&amp;gt;&amp;gt;&amp;gt; [&#39;I&#39;, &#39; &#39;, &#39; &#39;, &#39;w&#39;, &#39;a&#39;, &#39;n&#39;, &#39;t&#39;, &#39;s&#39;, &#39;s&#39;, &#39;s&#39;, &#39;u&#39;, &#39;c&#39;, &#39;c&#39;, &#39;e&#39;]&amp;gt;&amp;gt;&amp;gt; [&#39; &#39;, &#39; &#39;, &#39;I&#39;, &#39;a&#39;, &#39;c&#39;, &#39;c&#39;, &#39;e&#39;, &#39;n&#39;, &#39;s&#39;, &#39;s&#39;, &#39;s&#39;, &#39;t&#39;, &#39;u&#39;, &#39;w&#39;]입력된 값의 요소를 풀어서 반환한다. 반환되는 요소는 무작위로 반환된다! 또한, 요소의 총 개수가 1보다 작을 시 반환하지 않는다.elements()는 단순히 요소를 풀어서 출력해주며 대소문자를 구분한다!sorted()로 오름차순 정렬을 해주었다.most_common(n)import collectionsex_counter = collections.Counter([&#39;kim&#39;, &#39;kim&#39;, &#39;park&#39;, &#39;choi&#39;, &#39;kim&#39;, &#39;kim&#39;, &#39;kim&#39;, &#39;choi&#39;, &#39;park&#39;, &#39;choi&#39;])print(ex_counter.most_common())print(ex_counter.most_common(2))print(ex_counter.most_common(1))&amp;gt;&amp;gt;&amp;gt; [(&#39;kim&#39;, 5), (&#39;choi&#39;, 3), (&#39;park&#39;, 2)]&amp;gt;&amp;gt;&amp;gt; [(&#39;kim&#39;, 5), (&#39;choi&#39;, 3)]&amp;gt;&amp;gt;&amp;gt; [(&#39;kim&#39;, 5)]most_common(n)함수는 입력된 값의 요소들 중 빈도수(최빈값)을 n개 반환한다. 최빈값을 반환하므로 빈도수가 높은 순으로 상위 n개를 반환하며, 결과값은 Tuple자료형이다.most_common() 빈 값이면 요소 전체를 반환한다.most_common(2) 최빈값 상위 2개를 반환한다.most_common(n) 최빈값 상위 1개를 반환한다.substract()import collectionsex_counter1 = collections.Counter(&#39;I love you&#39;)ex_counter2 = collections.Counter(&#39;I love my family&#39;)# 2번 카운터 - 1번 카운터ex_counter2.subtract(ex_counter1)print(ex_counter2)&amp;gt;&amp;gt;&amp;gt; Counter({&#39;m&#39;: 2, &#39; &#39;: 1, &#39;l&#39;: 1, &#39;y&#39;: 1, &#39;f&#39;: 1, &#39;a&#39;: 1, &#39;i&#39;: 1, &#39;I&#39;: 0, &#39;v&#39;: 0, &#39;e&#39;: 0, &#39;o&#39;: -1, &#39;u&#39;: -1})substact() 는 말 그대로 요소를 빼준다. 만약, 요소가 없는 경우인데 subtract()를 진행했다면 음수의 값이 반환된다.이와 더불어, Counter 클래스는 산술, 집합연산이 가능하다. 이것이 정말 강력한 기능이다.2. combinations추가 예정." }, { "title": "[백준 21608] 상어 초등학교 - python", "url": "/posts/%EB%B0%B1%EC%A4%80-%EC%83%81%EC%96%B4%EC%B4%88/", "categories": "백준, 알고리즘", "tags": "백준, 시뮬레이션, 알고리즘", "date": "2022-03-09 00:00:00 +0900", "snippet": "Preview전형적인 시뮬레이션 문제이다. 때문에 문제에 제시된 조건들을 잘 따져가며 코딩하면 어렵지 않게 해결할 수 있다.문제 링크알고리즘 비어있는 칸 중에서 좋아하는 학생이 인접한 칸에 가장 많은 칸으로 자리를 정한다. 1을 만족하는 칸이 여러 개이면, 인접한 칸 중에서 비어있는 칸이 가장 많은 칸으로 자리를 정한다. 2를 만족하는 칸도 여러 개인 경우에는 행의 번호가 가장 작은 칸으로, 그러한 칸도 여러 개이면 열의 번호가 가장 작은 칸으로 자리를 정한다.문제에서 제시한대로 만족도 &amp;gt; 빈칸 &amp;gt; 행 &amp;gt; 렬 순의 우선순위로 좌석을 찾아야 한다.때문에 나의 코드는 다음과 같이 동작한다. 학생의 정보를 담은 리스트에서 한명씩 뽑아, 해당하는 학생을 문제의 조건에 맞는 위치에 자리시킨다. 위의 내용을 반복하여 모든 학생을 배치시킨 후 N*N행렬을 돌며 각 학생들의 만족도를 result 에 추가한다. result 를 출력한다.함수설명1. find_seat()학생의 정보를 입력받아 위의 문제의 조건을 만족시키는 행, 열을 반환하는 함수.def find_seat(info): max_count = -1 vacant_count = -1 r,c = 0,0 for i in range(N): for j in range(N): if not classroom[i][j]: cnt, vacant_cnt = check(i,j,info) if cnt &amp;gt; max_count: max_count = cnt vacant_count = vacant_cnt r,c = i,j continue if cnt == max_count: if vacant_cnt &amp;gt; vacant_count: vacant_count = vacant_cnt r,c = i,j continue return r,c2. check()행,열, 학생의 정보를 입력받아 해당하는 위치 주변의 공석, 좋아하는 사람의 수 를 반환하는 함수.def check(y,x,info): cnt = 0 vacant_cnt = 0 num, a,b,c,d = info for i in range(4): ny = y + dy[i] nx = x + dx[i] if 0 &amp;lt;= ny &amp;lt; N and 0 &amp;lt;= nx &amp;lt; N: if not classroom[ny][nx]: vacant_cnt += 1 if classroom[ny][nx] == a or classroom[ny][nx] == b or classroom[ny][nx] == c or classroom[ny][nx] == d: cnt += 1 return cnt, vacant_cnt전체코드import sysinput = sys.stdin.readlinedy = [-1,0,1,0]dx = [0,1,0,-1]def check(y,x,info): cnt = 0 vacant_cnt = 0 num, a,b,c,d = info for i in range(4): ny = y + dy[i] nx = x + dx[i] if 0 &amp;lt;= ny &amp;lt; N and 0 &amp;lt;= nx &amp;lt; N: if not classroom[ny][nx]: vacant_cnt += 1 if classroom[ny][nx] == a or classroom[ny][nx] == b or classroom[ny][nx] == c or classroom[ny][nx] == d: cnt += 1 return cnt, vacant_cntdef find_seat(info): max_count = -1 vacant_count = -1 r,c = 0,0 for i in range(N): for j in range(N): if not classroom[i][j]: cnt, vacant_cnt = check(i,j,info) if cnt &amp;gt; max_count: max_count = cnt vacant_count = vacant_cnt r,c = i,j continue if cnt == max_count: if vacant_cnt &amp;gt; vacant_count: vacant_count = vacant_cnt r,c = i,j continue return r,cN = int(input())likes = [0] * (N*N)classroom = [ [0] * N for _ in range(N)]counts = [ [0] * N for _ in range(N)]for i in range(N*N): s_num, a, b, c, d = map(int,input().split()) likes[i] = (s_num,a,b,c,d)for info in likes: r,c = find_seat(info) classroom[r][c] = info[0] counts[r][c] = [ item for item in info[1:]]result = 0for i in range(N): for j in range(N): count = 0 a,b,c,d = counts[i][j] for k in range(4): ny = i + dy[k] nx = j + dx[k] if 0&amp;lt;= ny &amp;lt; N and 0 &amp;lt;= nx &amp;lt; N: if classroom[ny][nx] == a or classroom[ny][nx] == b or classroom[ny][nx] == c or classroom[ny][nx] == d: count += 1 if count &amp;gt; 0: result += 10 ** (count - 1)print(result)결과" }, { "title": "[OPIc] IH 등급 시험 후기", "url": "/posts/OPIc-%ED%9B%84%EA%B8%B0/", "categories": "English, OPIc", "tags": "opic, english, test, roleplay", "date": "2022-03-09 00:00:00 +0900", "snippet": "Preview결론부터 말하자면, 첫 시험인데도 불구하고 IH를 받았다.정말로 기분이 아주 좋지 않을 수 없다. 참고로 본인은 평소 영어 공부에 그리 큰 관심이 있던 사람도 아니고 미국 드라마를 즐겨보는 편도 아니다. (시리즈를 통틀어 본 드라마는 딱 하나다 바로 ‘Friends’ 프렌즈는 제법 감명깊고 실제 영어 악센트나 발음에 정말 아주 0.01g정도 귀기울였다.) 영어 공부하려 본거는 진짜 아니다. 정말 진심으로 드라마가 재밌어서 봤고 사실 영어는 중간중간 재밌는 표현있을때만 신경썼을뿐.그럼에도 불구하고 운이좋게 IH등급이 나와버렸다. 아무래도 준비시간이 그렇게 중요한 시험이 아닌듯하다. (회화 위주이니)어찌되었든 내 경험이 조금이나마 다른사람들에게 도움이 될까 싶어 이 글을 포스팅 하였다.준비 과정처음에는 영어 회화시험이기에 준비함에 있어서 조금 난감함을 겪었다. 도대체 이걸 어디서 준비하지? 학원을 다녀야 하나..? 시험 유형도 한번 맛보고, (처음 겪었을 때는 진짜 쉽지않았다.) 그래서 정보를 찾던도중, 대부분의 블로그 후기에 오픽노잼 유튜브를 추천하는것을 확인하였다.https://www.youtube.com/c/opicnojam/featured - 오픽노잼 유튜브밑져야 본전이라는 마음에 유튜브 재생목록에 있는 강의를 시청하였는데 정말 ‘와우’ 와우 그자체였다. 생각보다 너무 도움되고 꿀팁이 넘쳐나는 강의다. 그래서 결론적으로 나는 이 시험을 응시하는데 시험 응시료 78,100 WON 빼고 아무 돈도 투자하지 않았다. 단지 저 유튜브 하나만 시청하였다.영상 시청 순서당연히 모든 강의를 시청하는 것이 제일 좋다 ^^. 하지만 모든 사람이 시간적 여유가 넘치는건 아니기에 내 경험상 꼭 필요한것을 위주로 설명을 해보자면,저 시리즈중 IH, AL 시리즈는 꼭 보는것을 적극 추천한다. (왼쪽에 쓰레기의 냄새가…)어찌 되었든, OPIc도 시험이고 ( 몰론 출제 문제가 너무 다양해서 시험문제 예측이 어렵기는 하다. ) 결국에는 어느정도의 유형은 있다. 크게 4가지로 나뉘는데, Description Habit Past experience Role-play이정도 되시겠다. 따라서 어느 문제든간에 저 4가지 범주안에는 포함이 되니 꼭 영상을 시청하고 대답을 하는 방향성이나 방법에대해 배워서 시험을 치루길 바란다. 내가 구구절절 여기에 각 유형별 대답하는 방법을 적기보다, 영상 시청이 100000배는 좋으니 설명은 더 굳이 안하겠다.위의 모든 영상을 시청후에는 유튜브에 OPIc 모의고사 (여우오픽, 오픽노잼, 등등 많이 있다.) 가 많이 있으니 실제 자신의 목소리를 녹음해보고 들어보며 피드백을 하면 좋은 성적이 나올것이다.모두 좋은 성적 거두기를 기원합니다.인증" }, { "title": "[백준] 나무재테크", "url": "/posts/%EB%B0%B1%EC%A4%80-%EB%82%98%EB%AC%B4%EC%9E%AC%ED%85%8C%ED%81%AC/", "categories": "백준, 시뮬레이션", "tags": "백준, 알고리즘, 시뮬레이션", "date": "2022-02-15 00:00:00 +0900", "snippet": "문제https://https://www.acmicpc.net/problem/16235알고리즘 본 문제는 시뮬레이션 문제로 나와있는 과정을 따라가면 그리 어렵지 않은 문제이다.하지만 중요한 구현상에 있어서 나무를 배열 하나에 저장할 시 시간 초과 문제를 해결할 수 없다.따라서 다음과 같이 배열을 세개 만들어야 한다.real_board : 매해 겨울에 추가되는 양분의 수를 담아둔배열 ,board : 실제 땅에 있는 양분을 담아둔 배열tree_board : 해당하는 땅에 들어있는 나무의 나이를 담아둔 배열구현 방식은 다음과 같다. tree_board 에 나무의 나이를 list 로써 저장한다. 봄 -&amp;gt; 여름 -&amp;gt; 가을 -&amp;gt; 겨울 순으로 코드를 구현함. 이때, 문제의 조건에 나이가 어린순으로 양분을 먹음으로 정렬을 해주어야 한다. 양분이 없어 죽은 나무는 dead_tree 에 값을 추가한다. 봄 여름이 지나감에 따라 땅의 양분, 나무의 나이를 갱신해준다. 가을은 각 나무의 나이가 5의 배수일 시 8방향으로 나이를 1 더해준다. 이때, 범위를 벗어나는 위치의 땅의 경우 갱신이 불가하므로 dy , dx list를 활용하여 값을 갱신한다. 겨울에는 매해 board 변수에 real_board 값을 더해준다. k 년동안 반복한 뒤 tree_count 변수 출력한다.import sysinput = sys.stdin.readlinedy = [-1,-1,-1,0,1,1,1,0]dx = [-1,0,1,1,1,0,-1,-1]N, M, K = map(int, input().split())real_board = [list(map(int, input().split())) for _ in range(N)]board = [ [5] * N for _ in range(N)]tree_board = [ [ [] for _ in range(N) ] for _ in range(N)]tree_count = 0for _ in range(M): x, y, z = map(int,input().split()) tree_board[x-1][y-1].append(z) tree_count += 1 for year in range(K): #spring for i in range(N): for j in range(N): if tree_board[i][j]: tree_board[i][j].sort() temp_tree, dead_tree = [], 0 for age in tree_board[i][j]: if age &amp;lt;= board[i][j]: board[i][j] -= age age += 1 temp_tree.append(age) else : tree_count -= 1 dead_tree += age // 2 board[i][j] += dead_tree tree_board[i][j] = [] tree_board[i][j].extend(temp_tree) #summer but did in spring #fall for i in range(N): for j in range(N): if tree_board[i][j]: for age in tree_board[i][j]: if age % 5 == 0: for k in range(8): nx = i + dy[k] ny = j + dx[k] if 0&amp;lt;= nx &amp;lt; N and 0 &amp;lt;= ny &amp;lt; N: tree_count += 1 tree_board[nx][ny].append(1) #winter for i in range(N): for j in range(N): board[i][j] += real_board[i][j] print(tree_count)" }, { "title": "[OPIc] Roleplay 유형", "url": "/posts/OPIc-Roleplay-%EC%9C%A0%ED%98%95/", "categories": "English, OPIc", "tags": "opic, english, test, roleplay", "date": "2022-02-13 00:00:00 +0900", "snippet": "1. Role- play 잘하는 법롤플레이는 11, 12, 13 질문으로 자주 출제되는 유형의 문제이다.대부분의 사람들이 ( 나 포함 ) 굉장히 어려워 하는 유형의 문제이지만, 유튜버 ‘오픽노잼’ 님이 알려주신 방법이라면 어렵지 않게 할 수 있다.2. Role-play #11 ( 상황에 대한 설명 ) 시작은 ‘hi’ or ‘hi, there’ 로 시작하자! Briefly explain your situation ( 사전 설명은 최대한 간단하게 하자 !) Ask your first question ( 첫번째 질문을 하자 ) Repeat the response ! ( 리액션을 반복하여 하자 ! 매우 중요 ) 2 more questions and repeat steps 1, 2, and 33. Role-play #12 ( 문제가 생겼을 시 대응 ) Explain the problem Ask the 1st question to resolve the probelm Response 는 No ! 로! Why not !? 물어보기. Repeat the response Feeling 으로 마무리! Ask the 2nd question to resolve the problem Response = Yes!! Repeat the response Feeling 으로 마무리 4. Role-play #13 MP ( 어떤 문제가 있었는지, 내가 어떻게 느꼈는지, 왜 그렇게 느꼈는지 ) 설명 ( 낮은레벨 : direct quotation , 높은 레벨 : indirect quotation ) 결론 ( 문제 해결 방법 보여주기 )항상 오픽노잼님이 강조하시는 것 : 스크립트 없이 연습하라!모든 상황의 대본을 준비하는 것은 역시 불가능에 가깝다.우리는 스크립트가 없지만 정형화된 패턴은 항상 익혀두고 그에 맞춰 이야기를 풀어가자 !" }, { "title": "[백준 17070] 파이프 옮기기1 - python", "url": "/posts/%EB%B0%B1%EC%A4%80-%ED%8C%8C%EC%9D%B4%ED%94%84-%EC%98%AE%EA%B8%B0%EA%B8%B01/", "categories": "백준, 다이나믹 프로그래밍", "tags": "백준, 알고리즘, 다이나믹 프로그래밍", "date": "2022-02-11 00:00:00 +0900", "snippet": "문제https://www.acmicpc.net/problem/17070[사용한 알고리즘] 다이나믹 프로그래밍 시뮬레이션[풀이]본 문제는 다이나믹 프로그래밍을 이용하면 쉽게 풀 수 있다. 그와 동시에 시뮬레이션 문제이므로 구현해야 하는 바를 잘 구현하여 풀도록 하자.문제의 조건은 다음과 같다. 처음에 설치된 파이프는 (1,1) (1,2) 에 위치하며 방향은 가로이다. 각 파이프가 설치된 모양에 따라 회전할 수 있는 방향이 결정된다. 회전 방향에 따른 공간이 비어있어야 한다.알고리즘 설명 dictionary 를 이용하여 각 방향의 회전 방향을 저장해둔다. ( 가로모양 : 0 , 대각선 모양 : 1 , 세로모양 : 2) cos 에는 방향에 따른 증가하는 dy, dx 를 저장한다. dp 테이블 ( 코드에서는 count ) 를 3차원 배열로 저장하여 dp[y][x][0, 1, 2] 에 각각 방향에 따른 경우의 수를 저장한다. dp 테이블에 값이 있다면 check함수를 실행한다. ( dp[y][x][0] == 0 이라면 y행x열에 해당하는 위치에 가로모양으로 파이프가 놓일 수 없었음을 의미하기에 check를 실행하지 않는다.) check 함수는 문제의 조건에 맞는 행동을 수행한다.코드import sysfrom collections import dequeinput = sys.stdin.readlineRIGHT_STRAIGHT = 0DIAGONAL_STRAIGHT = 1DOWN_STRAIGHT = 2def check(y,x,d): for direction in directions[d]: dy, dx = cos[direction] ny = y + dy nx = x + dx if ny &amp;lt; N and nx &amp;lt; N and not m[ny][nx]: if direction != 1: count[ny][nx][direction] += count[y][x][d] else: if not m[ny - 1][nx] and not m[ny][nx - 1]: count[ny][nx][direction] += count[y][x][d]N = int(input())m = [ list(map(int,input().split())) for _ in range(N)]count = [ [ [0] * 3 for _ in range(N) ] for _ in range(N)]# 0 : 오른쪽 1 : 대각선 2: 아래directions = { 0 : [0,1] , 1 : [0,1,2] , 2: [1,2]}cos = {0 : [0,1] , 1 : [1,1] , 2: [1,0]}count[0][1][0] = 1for i in range(N): for j in range(N): for d in range(3): if count[i][j][d] and not m[i][j]: check(i,j,d)print(sum(count[N-1][N-1]))" }, { "title": "[백준 14466] 소가 길을 건너간 이유2 - python", "url": "/posts/%EB%B0%B1%EC%A4%80-%EC%86%8C%EA%B0%80-%EA%B1%B4%EB%84%88%EA%B0%84-%EC%9D%B4%EC%9C%A02/", "categories": "백준, BFS", "tags": "백준, 알고리즘, bfs", "date": "2022-02-11 00:00:00 +0900", "snippet": "문제https://www.acmicpc.net/problem/14466[사용한 알고리즘] BFS 시뮬레이션[풀이]본 문제는 BFS 를 사용하여 구현하였다. 비교적 다른 문제들에 어렵지 않은 문제니 쉽게 해결이 가능하다. 그러나 본인은 국어를 못하여 문제를 읽고 이해를 못해서 좀 늦게 풀린 감이 있다..따라서 문제를 잘 읽어야한다.. 문제가 출력하길 요구하는것은 길을 건너지 않으면 만나지 못하는 소들의 쌍이다!!!문제의 조건은 다음과 같다. 농장에는 길이 존재한다. 인접한 목초지는 소들이 자유롭게 건널 수 있지만 일부는 길을 건너야 한다. 건너야 하는 길이 처음에 주어진다. 출력해야 하는 건 길을 건너지 않고서는 만날 수 없는 소들!알고리즘 설명 각 소의 위치를 cows 2차원배열에 담는다. ( cos[i][j] == 1 이라면 i행j열에 소가 존재한다는 의미이다. ) 각 소의 위치마다 BFS 를 수행한다. BFS 내에서 소의 상하좌우 위치에 길이 존재할 시 에는 탐색을 생략한다. ( 소가 길을 건너지 않았을 때가 조건이므로 ) 소가 탐색한 위치는 0 으로 값을 바꾸어준다. BFS 를 끝낸 뒤 cowmap 배열에서 1의 개수를 센뒤 count에 추가한다. 소의 쌍을 출력해야 하므로 count // 2를 출력한다. 약 20분내로 풀었던 문제이기에 코드가 깔끔하지 않다. 그만큼 비교적 쉬운 문제이고 나의 코드를 참고하기보다는 문제를 이해하고 구현에 집중하자.코드import sysfrom collections import dequeimport copyinput = sys.stdin.readlineN, K, R = map(int,input().split())farm = [ [[] for _ in range(N)] for _ in range(N) ]visited = [ [False] * N for _ in range(N)]dy = [-1,0,1,0]dx = [0,1,0,-1]cows = [ [0] * N for _ in range(N)]count = 0for _ in range(R): r1, c1, r2, c2 = map(int,input().split()) farm[r1 - 1][c1 - 1].append([r2 -1, c2-1]) farm[r2 - 1][c2 - 1].append([r1 - 1, c1 - 1])for _ in range(K): r, c = map(int,input().split()) cows[r-1][c-1] = 1def bfs(position, visit, cowmap): q = deque() q.append(position) while q: r, c = q.popleft() if visit[r][c]: continue else: visit[r][c] = 1 cowmap[r][c] = 0 for i in range(4): nr = r + dy[i] nc = c + dx[i] position = (nr,nc) po_list = [nr,nc] roads = farm[r][c] if po_list in roads: continue if 0 &amp;lt;= nr &amp;lt; N and 0 &amp;lt;= nc &amp;lt; N: q.append(position) return cowmapfor i in range(N): for j in range(N): if cows[i][j]: cowmap = bfs((i,j), copy.deepcopy(visited),copy.deepcopy(cows)) else : continue for k in range(N): for z in range(N): if cowmap[k][z]: count += 1print(count // 2)" }, { "title": "[백준 1800] 인터넷 설치 - python", "url": "/posts/%EB%B0%B1%EC%A4%80-%EC%9D%B8%ED%84%B0%EB%84%B7-%EC%84%A4%EC%B9%98/", "categories": "백준, 이분탐색", "tags": "백준, 알고리즘, 이분탐색", "date": "2022-02-10 00:00:00 +0900", "snippet": "문제https://www.acmicpc.net/problem/1800[사용한 알고리즘] 다익스트라 이분 탐색[알고리즘]본 문제를 처음 시도하였을때, 조합을 이용해 모든 인터넷 설치의 경우의 수를 구한 뒤, 각 경우의 수에 대한 연산을 해주었다. 결과는 몰론 당연하게도 메모리 초과로 실패하였다.생각해보면 P의 범위가 $1&amp;lt;=P&amp;lt;=10000$ 이므로 모든 조합의 경우의 수를 구하면, $_{10000}{C}_{1}$ + $_{10000}{C}_{2}$ + $…$ + $_{10000}{C}_{10000}$ $= 2^{10000}$ 이라는 어마어마한 숫자가 나온다. 아마 평생 계산해도 못끝냈을 양이다.d 즉 문제에서 P의범위를 제대로 보았다면 이러한 멍청한 연산은 하지 않았을 것이다. 고로 항상 문제를 잘 읽자..여하튼 이 문제는 검색을 해본 결과 이분탐색 + 다익스트라 를 이용한 풀이가 존재했다. 이것 또한 생각해보면, 각 노드간 가중치가 주어져 있기에 최소거리를 찾는다는 개념으로 다익스트라를 생각하고 접근하고 생각했어야 했는데 많이 부족했다.알고리즘 설명 이분 탐색을 수행한다. ( 즉 돈을 낼 최소 비용을 이분 탐색을 통하여 결정합니다. ) left , right 값을 통하여 mid값을 구합니다. 다익스트라를 수행합니다. 이때, 핵심은 최소 거리를 구하는 것이 아닌 지불할 수 있는 최소비용인 mid 값보다 큰 비용의 개수를 구하는 것 입니다. 따라서 distance[] 에는 mid 값을 넘긴 케이블의 수가 들어 있습니다. 즉 distance[n] &amp;gt; k 라면 n 까지 가는데 공짜 케이블 k개로는 해결할 수 없다는 의미입니다. 위의 과정을 계속 반복합니다. ( 즉 가장 적정의 값을 찾을 때 까지 반복한다는 의미 입니다. )import sysimport heapqinput = sys.stdin.readlineN, P, K = map(int,input().split())INF = 1e15graph = [[] for _ in range(N+1)]for _ in range(P): a, b, c = map(int,input().split()) graph[a].append((b,c)) graph[b].append((a,c))left, right = 0, 1000001answer = INFdef dijkstra(start, limit): q = [] distance = [INF] * (N+1) heapq.heappush(q, (0,start)) distance[start] = 0 while q: cost, index = heapq.heappop(q) if distance[index] &amp;lt; cost: continue for item in graph[index]: if item[1] &amp;gt; limit: if cost + 1 &amp;lt; distance[item[0]]: distance[item[0]] = cost + 1 heapq.heappush(q, (cost + 1, item[0])) else : if cost &amp;lt; distance[item[0]]: distance[item[0]] = cost heapq.heappush(q, (cost , item[0])) if distance[N] &amp;gt; K: return False else: return Truewhile left&amp;lt;= right: mid = (left + right) // 2 flag = dijkstra(1, mid) if flag: right = mid -1 answer = mid else : left = mid + 1 if answer == INF: print(-1)else : print(answer)참고 블로그 : https://jjangsungwon.tistory.com/125" }, { "title": "[ML 머신러닝] Mnist GAN 구현하기 (Code)", "url": "/posts/ML-GAN-mnistGAN/", "categories": "ML, 머신러닝, GAN, 간", "tags": "entropy, ml, 머신러닝, 간, 갠", "date": "2021-12-23 00:00:00 +0900", "snippet": "Preview오늘은 Mnist 데이터를 이용한 GAN 에 대한 실습을 진행해보려 한다. 즉 GAN을 이용하여 Mnist 이미지를 생성하는 코드라고 보면 되겠다. GAN에 대한 이론들이 궁금하다면 이전 포스터들을 봐주길 바란다!거두절미 할거없이 바로 코드로 가보자!Code먼저 필요한 패키지들을 **import 해주도록 하자.**import torchimport torch.nn as nnimport torch.optim as optimimport torchvision.utils as utilsimport torchvision.datasets as dsetsimport torchvision.transforms as transformsfrom torchvision.utils import save_imageimport osimport numpy as npimport matplotlib.pyplot as plt다음 GPU사용과 fake 이미지를 저장할 경로를 지정해주자.device = &#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;print(f&quot;device = {device}&quot;)# fake image 들을 저장할 경로sample_dir = &#39;samples&#39;if not os.path.exists(sample_dir): os.makedirs(sample_dir)하이퍼 파라미터 설정과 Mnist 데이터# 하이퍼파라미터 설정latent_size = 64hidden_size = 256image_size = 784 # 28 * 28num_epochs = 300batch_size = 100# Image Processingtransform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=[0.5], # 1 for gray scale 만약, RGB channels라면 mean=(0.5, 0.5, 0.5) std=[0.5])]) # 1 for gray scale 만약, RGB channels라면 std=(0.5, 0.5, 0.5)# MNIST 데이터셋mnist_train = dsets.MNIST(root=&#39;data/&#39;, train=True, # 트레인 셋 transform=transform, download=True)mnist_test = dsets.MNIST(root=&#39;data/&#39;, train=False, transform=transform, download=True)데이터가 잘 받아졌는지 확인하기 위해 9개만 출력해보겠습니다.# 랜덤으로 9개만 시각화figure = plt.figure(figsize=(8, 8))cols, rows = 3, 3for i in range(1, cols * rows + 1): sample_idx = torch.randint(len(mnist_train), size=(1,)).item() img, label = mnist_train[sample_idx] figure.add_subplot(rows, cols, i) plt.axis(&quot;off&quot;) # x축, y축 안보이게 설정 plt.imshow(img.squeeze(), cmap=&quot;gray&quot;)plt.show() 데이터 로더# 데이터 로더data_loader = torch.utils.data.DataLoader(dataset=mnist_train, # 훈련용 데이터 로딩 batch_size=batch_size, shuffle=True) # 에폭마다 데이터 섞기모델 정의하기# DiscriminatorD = nn.Sequential( nn.Linear(image_size, hidden_size), nn.LeakyReLU(0.2), nn.Linear(hidden_size, hidden_size), nn.LeakyReLU(0.2), nn.Linear(hidden_size, 1), nn.Sigmoid()) # Binary Cross Entropy loss 를 사용할 것이기에 sigmoid 사용!# Generator G = nn.Sequential( nn.Linear(latent_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, image_size), nn.Tanh())# Device settingD = D.to(device)G = G.to(device)Loss function 설정, Optimizer 설정criterion = nn.BCELoss()d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)모델 훈련dx_epoch = []dgx_epoch = []total_step = len(data_loader)for epoch in range(num_epochs): for i, (images, _) in enumerate(data_loader): images = images.reshape(batch_size, -1).to(device) # Create the labels which are later used as input for the BCE loss real_labels = torch.ones(batch_size, 1).to(device) fake_labels = torch.zeros(batch_size, 1).to(device) # ================================================================== # # Train the discriminator # # ================================================================== # # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x)) # Second term of the loss is always zero since real_labels == 1 outputs = D(images) d_loss_real = criterion(outputs, real_labels) real_score = outputs # Compute BCELoss using fake images # First term of the loss is always zero since fake_labels == 0 z = torch.randn(batch_size, latent_size).to(device) fake_images = G(z) outputs = D(fake_images) d_loss_fake = criterion(outputs, fake_labels) fake_score = outputs # Backprop and optimize d_loss = d_loss_real + d_loss_fake reset_grad() d_loss.backward() d_optimizer.step() # ================================================================== # # Train the generator # # ================================================================== # # Compute loss with fake images z = torch.randn(batch_size, latent_size).to(device) fake_images = G(z) outputs = D(fake_images) g_loss = criterion(outputs, real_labels) # Backprop and optimize reset_grad() g_loss.backward() g_optimizer.step() if (i+1) % 200 == 0: print(&#39;Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}&#39; .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), real_score.mean().item(), fake_score.mean().item())) dx_epoch.append(real_score.mean().item()) dgx_epoch.append(fake_score.mean().item()) # real image 저장 if (epoch+1) == 1: images = images.reshape(images.size(0), 1, 28, 28) save_image(denorm(images), os.path.join(sample_dir, &#39;real_images.png&#39;)) # 생성된 이미지 저장 fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28) save_image(denorm(fake_images), os.path.join(sample_dir, &#39;fake_images-{}.png&#39;.format(epoch+1)))# 생성자, 판별자 각각 모델 저장torch.save(G.state_dict(), &#39;G.ckpt&#39;)torch.save(D.state_dict(), &#39;D.ckpt&#39;)결과 확인plt.figure(figsize = (12, 8))plt.xlabel(&#39;epoch&#39;)plt.ylabel(&#39;score&#39;)x = np.arange(num_epochs)plt.plot(x, dx_epoch, &#39;g&#39;, label=&#39;D(x)&#39;)plt.plot(x, dgx_epoch, &#39;b&#39;, label=&#39;D(G(z))&#39;)plt.legend()plt.show()결론결과 확인 이미지를 보면, 두개의 Loss가 0.5 로 수렴하는걸 볼 수 있다.Referencehttps://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/generative_adversarial_network - 최윤제님 github" }, { "title": "[ML 머신러닝] Jenson-Shannon-divergence", "url": "/posts/ML-jenson-divergence/", "categories": "ML, 머신러닝, Jenson-Shannon-divergence", "tags": "entropy, ml, 머신러닝, 다이벌전스, JSD", "date": "2021-12-22 00:00:00 +0900", "snippet": "Jensen-Shannon Divergence를 왜 사용하는가오늘은 약간의 KL-divergence의 복습과 ‘Jensen-Shannon Divergence‘에 대해서 알아보도록 하겠다.KL-divergence?아마 누군가는 이렇게 생각할 수도 있다. ‘이미 KL-divergence’가 존재하는데도 불구하고 왜 또다른 개념이 나왔을까? 그 이유와 과정에 대해 먼저 짚고 넘어가자.지난 시간에 포스팅했지만, KL-divergence는 두 확률분포의 유사도를 나타내는 값이라 할 수 있다. 즉 P가 실제 target값 Q가 예측값으로 실제와 예측값의 차이가 얼마나 괴리감이 있는가?에 대한 척도를 나타내는 값이였다. 하지만 많은 사람들이 착각하는것이, ‘KL-divergence’는 두 확률분포의 거리를 의미한다라고 생각하는데, 전혀 아니다. 일단 KL-divergence 는 symmetric 하지 않다. 즉 대칭성을 띄지 않는다. 예를들어 $D_{KL} (P \\parallel Q) \\ne D_{KL} (Q\\parallel P)$이다. 거리의 값을 의미한다면 두개의 값은 같아야한다.Jenson-Shannon-Divergence이러한 부분을 보완하기위해 거리개념 Distance Metric으로 쓸 수 있는 방법에 대해 나온것이 Jenson-Shannon-Divergence이다.식을 먼저 살펴보면 다음과 같다.$$JSD(P,Q) = \\frac{1}{2} D(P\\parallel M) + \\frac{1}{2} D(Q\\parallel M)$$$$where M = \\frac{1}{2} (P+Q)$$ 식을 살펴보면, M은 P와 Q의 중간값을 의미한다. 각각 M과 KL-divergence를 함으로써 값이 Symmetry해짐을 알 수 있다.따라서 다음이 성립한다.$$JSD(P,Q) = JSD(Q,P)$$이를 통하여 우리는 두 확률분포 사이의 거리(distance)를 JSD를 통해 척도로 사용이 가능해짐을 알 수 있다.Referencehttps://aigong.tistory.com/66 - 아이공의 AI 공부 도전기" }, { "title": "[ML 머신러닝] GAN - 정복하기 (5) GAN의 종류 - 3", "url": "/posts/ML-GAN-GAN_5/", "categories": "ML, 머신러닝, GAN, 간", "tags": "entropy, ml, 머신러닝, 간, 갠", "date": "2021-12-22 00:00:00 +0900", "snippet": "Preview이전 시간에 이어 GAN의 종류에 대해서 조금 더 알아보겠다. 이전 GAN들과는 조금 다른 확장된 개념이 등장하니 집중하자.CycleGAN두 개의 Unpaired 한 이미지가 있을 때, 해당 이미지를 가지고 새로운 이미지를 만드는 방식이다.Unpaired 이미지와 Paired 한 이미지가 무엇인가?다음 그림을 보면 한방에 이해가 갈 것이다.Paired 이미지의 경우 서로 어느 정도 쌍이 되는, 이미지를 말한다. 위 그림에서 Paired 이미지는 얼룩말의 윤곽과 얼룩말의 사진을 나타내고 있다.하지만 실제 현실 세계에서 이와 같이 똑같은 모습의 데이터를 찾는 것은 매우 어렵고 비용 또한 많이 든다. 따라서 완전히 다른 Unpaired 데이터임에도 효과적으로 학습을 진행하는 방법이 바로 CycleGAN이다.그렇다면 이제 Cycle GAN의 대략적 진행과정을 살펴보자. 먼저 기존 GAN와의 차이점은 CycleGAN에는 Noise가 섞여 들어가지 않는다. 또한, D는 G로부터나온 이미지를 판별한다. D에는 domain B에 해당하는 (예를들어 G가 일반 말을 생성해낸다 하면 일반 말 사진으로 학습을시킨다.)하지만 이때, 굉장히 큰 문제가 하나 발생한다.G의 입장에서 생각해보자. G의 목적은 D를 속이는 것 이다 그렇다면 G는 D를 더 잘 속이기 위하여 이미지를 변형시킬텐데, 그 과정속에서 기존의 얼룩말의 형태가 바뀌고 (예를들어 가만히 서있던 말이 뛰는 말이 되는 경우 : 이 과정이 만약 D를 속이는데 더 유리하다면 G는 그렇게 진화할것이다.) 뒤틀릴 수 있다.이러한 상황은 우리가 원하는 방향이 아니다. 우리는 얼룩말을 일반말로 바꾸고 싶은 상황이다. 그 상황속에서 얼룩말의 자세가 변하거나 하는 상황은 정말 의미가 없을것이다. (예를들어 당신이 기본말의 데이터셋이 필요하다고 하자, 이때 해본자는 알겠지만 데이터를 모으기는 어려운일이다. 때문에, 얼룩말 사진을 이용하여서 기본말의 사진으로 바꾸고 그 데이터또한 수집하자고 하자. 이때 당연히 구도가 변하면 곤란하겠지?)때문에 CycleGAN이 필요한 것이다.이러한 변화를 해결하기 위하여 다음 이미지가 등장한다.Generator 가 제일 처음 얼룩말 이미지를 가지고 말 모양의 Fake 이미지를 생성하는 데 이를 기반으로 다시 얼룩말 이미지를 생성해 보게 한다.이렇게 함으로써 Generator 은 마구잡이로 모양을 변경할 경우 다시 얼룩말 이미지로 돌아오기 힘들다는 것을 학습하며, 모양은 유지하며 내부에 색과 같은 값들을 변화 시킨다.Reference https://www.youtube.com/watch?v=odpjk7_tGY0 - youtube, 1시간만에 GAN정복하기 https://m.blog.naver.com/euleekwon/221559102854 - EuleeKwon’s Blog" }, { "title": "[ML 머신러닝] GAN - 정복하기 (4) GAN의 종류 - 2", "url": "/posts/ML-GAN-GAN_4/", "categories": "ML, 머신러닝, GAN, 간", "tags": "entropy, ml, 머신러닝, 간, 갠", "date": "2021-12-22 00:00:00 +0900", "snippet": "Preview이번 포스트또한 지난시간에 이어서 GAN의 종류에 대해 알아보는 시간을 가진다.Semi-Supervised GAN(SGAN)비교적 간단한 모델이다.Discriminator 에게 가짜 진짜 구분의 역할 뿐만아니라, Class를 구분하여 추가로 Fake라는 Class또한 구분하게 만든것을 SGAN이라 한다.예를들어 G가 Fake 숫자 MNIST 이미지를 생성해낸다면, Discriminator는 그 사진이 Fake 인지 아닌지를 구분함과 동시에 Real 이미지일시 Class를 구분하여 분류한다. Mnist 데이서셋으로 가정한다면, ​Real Image 0 이 들어왔을 때, Discriminator는 0을 나타내는 one-hot vector를 반환한다.이때, 위의 사진에서 보듯이, G에게는 Noise, One-hot-vector가 들어가게 되는데, Generator는 One-hot vector에 들어온 숫자를 통하여 Class를 생성해낸다.Auxiliary Classfier GAN (ACGAN)위의 SGAN과 유사하다.하지만 가장 중요한 차이점이 하나 존재한다. D가 두개의 Classifier로 구성되어 있다는 점즉 D는 하나의 분류기에서는 가짜, 진짜를 판별하고, 또 다른 하나의 분류기에서는 데이터의 범주 (Class)를 판별한다.이 덕분에 ACGAN으로 생성된 데이터는 다른 분류기에 넣더라도 범주 분류에 있어서 뛰어나다고 한다. 즉 이치에 맞는 데이터를 잘 생성해낸다고 한다.따라서 ACCGAN의 Discriminator 은 multi-task learning 이라고도 불린다.다음은 ACGAN의 아키텍처이다.Reference https://ratsgo.github.io/generative%20model/2017/12/21/gans/ - ratsgo’s blog https://m.blog.naver.com/euleekwon/221559102854 - EuleeKwon’s Blog" }, { "title": "[ML 머신러닝] KL-divergence", "url": "/posts/ML-KL-divergence/", "categories": "ML, 머신러닝, Information, 정보, KL-divergence", "tags": "entropy, ml, 머신러닝, 정보, 다이벌전스, kl-divergence, information", "date": "2021-12-21 00:00:00 +0900", "snippet": "Title오늘은 KL-divergence 에 대해서 알아보겠다. 하지만 이 개념을 설명하기 앞서서, 미리 알아야할 내용들이 있기때문에 그 내용들을 먼저 설명하고 진행을 하겠다.Cross Entorpy크로스 엔트로피를 한마디로 정의하자면, ‘예측과 달라서 생기는 정보량’ 이라 할 수 있다. 딥러닝을 조금이라도 공부한 사람이라면 모를리 없을테지만 초심자를 위히여 보다 자세히 설명하겠다.먼저 Binary Case에 대해서 알아보자.Binary case 의 Cross Entorpy알다싶이 binary case 의 경우 0, 1 두개의 상황만이 존재한다. $y$를 target $\\hat{y}$ 예측값이라 한다. 이때 다음과 같은 식이 성립한다.$$BCE = -ylog(\\hat{y}) - (1 - y)log(1 - \\hat{y})$$따라서 target의 값과 예측값 $\\hat{y}$값이 같다면 0 아니라면 무한대가 나옴을 알 수 있다.여러가지 case에 대한 Cross EntropyBinary의 경우 Cross Entropy의 값이 타겟값과 모델의 출력값이 다른 정도를 나타냄을 알 수 있다.따라서, 다음의 경우처럼 식을 제시할 수 ‘도’ 있다.$$BCE = \\sum_{x\\in0,1} (-P(X)log(Q(X)))$$ $P(X)$는 희망하는 타겟값을 의미한다. $Q(X)$는 모델이 출력한 값(예측값)을 의미한다.이를 조금 더 일반화하여, 다음과 같이 식을 제시할 수 있다.$$CE = \\sum_{x\\in X} (-P(x)log(Q(x)))$$그렇다면 위의 식으로 유도되는 의미는 무엇일까?그것은 CE는 Q라는 모델의 결과에 대해 P라는 이상적인 값을 기대했을 때 우리가 얻게되는 ‘어지러움(?)’에 대한 값을 정보량으로 표현한 것이라는 점이다. 내가 참고한 블로그는 어지러움을 ‘놀라움’ 으로 표현하였다. 난 개인적으로는 ‘엔트로피’라는 말에 걸맞게 어지러움 이라고 표현을 하였다.위의 식을 가지고 예제에 적용시켜보자! 정상적인 주사위가 있다. 몰론 확률은 1/6 비정상적 주사위 또한 존재한다. 확률은 그냥 랜덤. (합은 1)따라서 위의 두 주사위의 CE 를 계산하면, 비정상적 주사위의 CE 결과값이 더 높다.즉 비정상적인 주사위가 더 ‘어지러움’ 의 정도가 크다는 것이다. (랜덤성이 크다 라고 해석해도 될것같다.)KL dirvergence드디어 대망의 KL divergence이다. 먼저 내가 공부한 바에 의한 정의를 설명하자면‘P 분포와 Q 분포가 얼마나 다른지를 측정하는 방법. 여기서 통계적으로 P는 사후, Q는 사전분포를 의미한다.’ 사후분포(사건이 일어난 후의 분포)란 당연히 결과값 (target)을 의미하고 Q사전분포는(사건이 일어나기 전의 분포) 당연히 예측값을 의미한다.텐서플로우 공식 문서에 정의되어있는 용어로 설명해보면, KLD는 y_true(P)가 가지는 분포값과 y_pred(Q)가 가지는 분포값이 얼마나 다른지를 확인하는 방법이다.즉! KLD는 값이 낮을수록 두 분포가 유사하다라고 해석한다.따라서 수식으로 보도록 하자.$$D_{KL} (P\\parallel Q) = \\sum_{x\\in X}P(x)log_b (\\frac{P(x)}{Q(x)})$$위 식을 전개한다면,$$-\\sum_{x\\in X} P(x)log_b (\\frac{P(x)}{Q(x)})$$$$=&amp;gt; -\\sum_{x\\in X} P(x)lob_b Q(x) + \\sum_{x\\in X} P(x)log_b(P(x))$$위의 식은 각각 기댓값으로 표현할 수 있으므로,$$=&amp;gt; -E_P [log_b (Q(x))] + E_P [log_b P(x)]$$$$=&amp;gt; H_P (Q) - H(P)$$즉 P의 기준으로 봤을 때의 Q에 대한 크로스 엔트로피를 의미하고 H(P)는 P에 대한 정보 엔트로피를 의미한다.위의 사진을 볼때, 초록색의 넓이가 KL-divergence 의 값을 의미한다. 즉 두 확률분포가 유사하다면, 그 값이 작을것이고 유사하지않다면 그 값이 클것이다.때문에, KL-divergence가 분포값이 얼마나 다른지를 측정하는 식이라고 할 수 있다.Referencehttps://angeloyeo.github.io/2020/10/27/KL_divergence.html - 공돌이의 수학정리노트" }, { "title": "[ML 머신러닝] 정보-엔트로피 (information-entropy)", "url": "/posts/ML-%EC%A0%95%EB%B3%B4%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC/", "categories": "ML, 머신러닝, Information, 정보", "tags": "entropy, ml, 머신러닝, 정보, information", "date": "2021-12-20 00:00:00 +0900", "snippet": "정보 엔트로피이번 시간에는 정보엔트로피에 관해 알아보겠다. 아마 처음 보는 사람은 정보에도 엔트로피가 존재하는가? 에 대해 의문을 가질 것이다. (나 또한 그랬으니까)따라서 이번 시간에 자세히 알아보도록 하자!정보(information)정보에대해 알아보기 전에 우리가 알아볼 정보(information)는 단순히 통계학적 관점임을 알고 공부하도록 하자.가령 예를들면, 데이터베이스의 관점에서는 데이터를 쉽게 사용할 수 있도록 가공한것을 정보라 할 수 있다.하지만 통계학적 관점이라면..? 통계학적 관점에서 정보는 사건(event)가 일어날 확률을 낮춰주는 일종의 증거(?)이다. 즉 정보가 많을수록 확률은 낮아진다 여기에 대해 잘 이해가 안될 수 있는데 예를들어 누군가가 당신에게 사막에 눈이 올 확률을 물어본다고 해보자 당신은 몇 %의 확률을 예상할까? 아마 당연히 5% 미만 혹은 아주 작은 수의 확률을 예상할 것 이다. 어째서일까? 이유는 당신은 이미 사막에 관련된 간단한 지식 (덥다던지, 건조하다던지) 들을 (이것을 우리는 실제로도 정보라고 부르지 않는가? ㅎㅎ) 알고 있기 때문이다. 이러한 이유로 통계학의 관점에서 정보량이 많을수록, 확률은 낮게 예측된다고 본다. 때문에 이러한 수식이 성립한다.$$정보량 \\propto \\frac{1}{P(X)}$$즉 정보량은 확률에 반비례한다.정보량조금 더 구체적으로 하자면, 통계학에서의 정보량은 다음과 같이 정의한다.랜덤변수 $X$에 대해서$$I(X) = -log_b (P(X))$$ b는 2, e, 10중 하나를 의미한다.굳이 log 를 붙인 이유는 확률값(혹은 롹률밀도 값)에 반비례해야 하기 때문. 두 사건의 정보량을 합치면 각 사건의 정보량을 합친 것과 같아야 함.라고 할 수 있다.엔트로피 (평균 정보량)통계학에서 엔트로피는 평균 정보량을 의미한다고 한다. 열역학이나 다른 여러가지 역학을 배운 공학도들은 엔트로피가 평균 정보량이라는 것에 대해서 이해하지 못하겠지만 어쩔수없다. 누군가가 미리 이렇게 정의해놓은걸.. 그냥 받아들이자. 그냥 열역학에서 배운 엔트로피와는 관계가 전혀 없다고 한다 ^^.따라서 이산 랜덤변수 $X$의 샘플 공간이 ${x_1,x_2,x_3,…,x_n}$ 이라고 할때,다음과 같이 정의된다. $$H(X) = E[I(X)] = - \\sum_{i=1}^n P(x_i)log_b (P(x_i))$$여기서 $E$는 기댓값 연산자를 의미한다.Referencehttps://angeloyeo.github.io/2020/10/26/information_entropy.html - 공돌이의 수학정리노트" }, { "title": "[ML 머신러닝] GAN - 정복하기 (3) GAN 의 종류", "url": "/posts/ML-GAN-GAN_3/", "categories": "ML, 머신러닝, GAN, 간", "tags": "gan, ml, 머신러닝, 간, 갠", "date": "2021-12-19 00:00:00 +0900", "snippet": "Preview이번 포스트에서는 GAN의 종류에 대해 알아보는 시간을 가지겠다.보통의 딥러닝 Network들과 같이 GAN또한 많은 종류의 형태와 종류들이 있다.DCGAN(Deep Convolution GAN)DCGAN은 Deep Convolutional Generatice Adversarial Network의 약자로, GAN을 개선시키고 거기에 Convolution을 적용한 모델입니다.출처: 미미로그 https://memesoo99.tistory.com/32 대부분의 내용은 위 블로그를 참조하여 작성하였다. 본 블로그보다 훨~씬 자세한 설명이 있으니 깊게 공부하고 싶은 사람은 위 블로그를 참조하자!Ian Goodfellow가 처음 제안한 적대적 생성 신경망(GAN)은 획기적이었으나 구조가 다소 불안정하고, NN이 기본적으로 지닌 Black Box 한계점 = ‘어떠한 과정을 거쳐서 이런 결과가 나오는거지?’에 대한 설명이 부족했다.때문에 논문에서는 DCGAN 을 통하여 다음 내용들을 보완한다고 설명한다. 거의 대부분의 상황에서 안정적 학습이 가능한 GAN인 DCGAN을 제시한다. 학습이 된 판별기(이하 D)가 이미지 분류에서 다른 비지도 알고리즘들과 비교했을때 대등한 성능을 보인다. DCGAN이 학습한 filter들을 visualize하고, 특정 filter가 특정 object를 생성하는 역할을 한다는것을 알아냈다. DCGAN이 벡터 산술 연산이 가능한 성질을 갖는다. Semantic quality를 갖는다.여기서 주목해야할 부분은 3번과 4번의 특징이다. 아주 흥미로운 점이다.3번의 예를 들자면, 방(room)의 사진을 생성해내는 G가 있다고 해보자. 이때, 방이라면 당연히 창문이 존재할 것 이다. 3번의 특징이 여기서 발현된다. G의 filter에서 창문을 생성해내는 특징을 색출하고 그 특징을 dropout 하면 특징이 사라지게 된다. 즉 창문이 없는 방을 생성해낼 수 있다.4번의 내용은 글로 봐서는 어떠한 내용인지 잘 감이 오지 않을텐데, (벡터 산술 연산..? 그게 뭐지) 내가 이해한걸 토대로 쉽게 설명하자면 (웃는여자) - (여자의 특성) + (남자의 특성) = (웃는 남자) 의 사진을 생성해낼 수 있다는 의미이다!방법은 이러하다. 각 카테고리 (웃는여자), (일반적여자), (일반적남자) 의 z를 평균을 내어 Z vector 를 생성한다. 평균값을 구한 각 Z vector들을 연산한다. 위의 에시처럼 웃는여자 - 여자 + 남자 결과적으로 웃는 남자의 얼굴이 생성된다.보다 자세한 내용이 알고 싶다면, 위의 링크를 참조하여 공부하도록 하자.Least Squares GAN(LSGAN) 먼저 (b)의 이미지를 볼 필요가 있다. (b)의 이미지에서 파란색 선(Decision Boundary)를 기준으로 아래는 Real, 위는 Fake로 간주한다고 생각해보자. 현재 분홍색으로 표시되어 있는 별모양에 집중해보면, 저 이미지들은 Fake임에도 불구하고, Boundary를 기준으로 아래에 있다는 이유로 Real이미지로 분류되어 있다. 이때, G의 입장에서 생각해보면 저들은 이미 ‘진짜’로 분류되어지기 때문에 더이상 학습될 필요가 없다. 이를 위해 Least suqare loss를 사용하여 (기존의 GAN은 Binary cross entropy를 사용한다) 멀리 있는 sample에게 더 큰 패널티를 부여하여 저들을 좀더 Real image의 Boundary로 끌고 오자는게 목적이다. 그 결과 (a)에서 멀리있는 Fake Sample 들이 더 큰 패널티를 부여받음으로써, 좀 더 Real Image 의 Boundary로 끌고 와짐을 확인할 수 있다.이처럼, 거리가 멀수록 큰 패널티를 얻기 때문에, 가짜 이미지들은 거리를 좁히는 방향으로 새로 생성되게 된다.나머지 내용은 다음시간에~Referenceshttps://di-bigdata-study.tistory.com/12 - 미미로그" }, { "title": "[ML 머신러닝] GAN - 정복하기 (2)", "url": "/posts/ML-GAN-GAN_2/", "categories": "ML, 머신러닝, GAN, 간", "tags": "gan, ml, 머신러닝, 간, 갠", "date": "2021-12-18 00:00:00 +0900", "snippet": "GAN - 기본 수식지난시간에 이어 수식에 대해 알아보겠다.수식수학에 익숙치 않거나, 이런 수식을 많이 접하지 안해본 사람들은 의아할 것이다.도대체 저 $min, max$는 뭘까..?결론부터 말하자면,왼쪽에서 G는 V(D, G) 가 최소(min) 가 되려 하고, D는 V(D, G) 최대(max) 가 되려고 한다는 의미이다.D의 입장?구별 모델인 D의 입장에서 생각해보자. D는 경찰이다. 가짜 데이터에는 0을 출력하고, 진짜 데이터에는 1을 출력해야 한다. x는 진짜 데이터고, G(z)는 G가 z를 가지고 만든 가짜 데이터이다. 따라서 D는 오른쪽 수식 중, D(x) = 1이 되어야 하며, D(G(z))는 0 이 되도록 하는 것이 최대 목표이다.즉 D의 목적은 $logD(x)$ 의 값이 최대가 되는 것임에는 이변이 없다.여기서 의문이 하나 든다. log D(x) 의 값은 최대 0의 값을 가지지 않나..?분명 값이 최대가 되는것이 목표인데, $logD(x)$의 값은 최대 0이다..하지만 신경쓰지 않아도 된다. 즉 무슨 말이냐면, $logD(x)$의 값이 0이지만, 그 값은 어찌되었든 최대란 것이다. 그러므로, D의 입장에서는 0이 최대이기에 수식의 값 $V(D,G)$의 값이 0이 되는 것이 최고의 상황이란 뜻이다.따라서 D는 0에 가까운 숫자로 가기 위해 노력하는 것을 최대(max)가 되려 한다 하고, 이를 max D로 표현한 것이다.G의 입장다음은 G의 입장에 대해 알아보겠다.수식의 이미지 부터 확인하자.V(D, G) 은 GAN의 Loss 함수, Objective 함수라고 불리며, G의 목적은 V(D, G) 가 최소가 되도록 하는 것을 의미한다. G는 위조지폐범이다. 경찰과 반대로 G는 D가 가짜 데이터에 대해 1을 출력하게 해야 한다. D가 진짜 데이터를 제대로 구별하는지 아닌지는 별로 상관이 없다. x는 진짜 데이터고, G(z)는 G가 z를 가지고 만든 가짜 데이터이다. 따라서 오른쪽 수식 중, D(x) = 0이 되어야 하며, D(G(z))는 1 이 되도록 해야 한다.G가 원하는 상황은 다음과 같다. 앞에서 D가 어떻게 하는지는 상관이 없다. 다만 뒤에서 D(G(z))가 1이 되게 해야 한다.log(1-1)으로 인해 log 0 이 된다면 해당 값은 -infinity를 향하게 된다.이는 매우 매우 0보다도 작은 무한대의 음수로, 결국 G의 목표는 엄청 엄청 작은 0 보다 작은 음의 무한대를 향하는 것이 목적이라고 볼 수 있다. 따라서 G가 원하는 최적의 상황은 매우 매우 작은 음의 무한대가 되는 방향이 되는 것이다.Referencehttps://www.youtube.com/watch?v=odpjk7_tGY0 - 고려대 최윤제 (1시간만에 GAN 정복하기)" }, { "title": "[ML 머신러닝] GAN - 정복하기 (1)", "url": "/posts/ML-GAN-GAN_1/", "categories": "ML, 머신러닝, GAN", "tags": "gan, ml, 머신러닝", "date": "2021-12-18 00:00:00 +0900", "snippet": "GAN (Generative Adversarial Network)직역하자면 다음과 같다.생산적 적대 신경망이 무슨 말이란 말인가. 항상 느끼지만 한국어는 공부를 하는 입장에서 한문이 너무 많아서 괴롭다. 그 어느 누가 생산적 적대 신경망 이란 말을 보고 이해할 수 있을까. 따라서 저런 말은 집어치우고, 본인이 이해한 쉬운 그림을 보고 설명하겠다.위조지페범과 경찰다음과 같은 상황을 생각해보자. 위조지폐범이 지폐를 위조하였다. 경찰의 수사망에 올라 경찰은 위조지폐를 추적하였다. 그걸 안 위조지폐범은 더더욱 철저하게 지폐를 위조하였다. (수사망에 올라가지 않게 즉, 경찰이 위조지폐인지조차 모르게) 고도의 발달된 기술의 범인을 잡기위하여 경찰또한 고도의 기술을 도입하여 위조지폐 판별에 힘썼다. 위의 내용을 무한 반복한다.믿기 힘들겠지만 위의 내용이 GAN(Generative Adversarial Network)의 내용이다. 위의 내용을 반복하다보면 위조지폐범은 결국 진짜 지폐와 구별할 수 없는 지폐를 만들어내게 될것이다.Models아직 위의 설명으로는 감이 잘 오지 않을 수 있다. 하지만 걱정마라. 그건 당신 뿐만이 아닌 세상 99%의 모든 사람들이 그렇다.. 몰론 나 포함. 천천히 밑의 글과 내용을 읽어가며 공부하면 해결될 것 이라고 생각한다.GAN 은 다음과 같은 두가지 모델로 구성된다. 첫번째 Discriminative Model 두번째 Generative Model 여기서 생성모델(Generative Model)의 역할이 위조지폐범이 되고, 구별모델 (Discriminative Model)의 역할이 경찰의 역할이 된다.구별모델은 사진을 보고, Class를 구분하여 사진을 판별하고 (ex: 진짜면 1, 가짜라면 0) 생성모델은 랜덤한 코드를 받아 가짜 이미지를 생성해 낸다.GAN의 목적위에서 말했다 싶이, GAN 의 목적은 $P_{data} (x) , P_{model} (x)$ 의 확률 분포의 차이를 줄이는 것을 목적으로 한다.사진으로 포현하면 다음과 같다.기본 수식따라서 위의 목적을 만족하기 위해, 구별모델 과 생성모델 의 수식을 표현하자면 다음과 같다. $z$의 의미는 noise 이다. (랜덤한 숫자로 뿌려진 noise) $z$ 즉 noise를 통하여 위조지폐범이 만든 지폐를 $G(z)$라 하자. 이제 Discriminator(경찰) 이 위조지폐와 실제 지폐를 구분해야 한다. 경찰은 이게 위조지폐라면 0을 출력하고, 진짜 지폐라면 1을 출력하기로 한다. 위조지폐 $G(z)$ 와 실제 지폐 x 가 경찰 손으로 들어갔을 때, $D(G(z))$는 위조지폐이기 때문에 0, 실제 지폐는 $D(x)$는 1을 출력하게 된다.즉 경찰이 위조지폐와 진짜지폐를 잘 구분한다면, $D(G(z))$가 0 이 되고 $D(x)$는 1이 되므로 최댓값을 가질 수 있다.반면 위조지폐범의 입장에서는 경찰을 속여야 하므로, 당연히 $D(G(z))$가 1의 됨을 목표로 한다.수식에 대한 자세한 설명은 다음 게시물에 이어 작성하겠다.Referencehttps://www.youtube.com/watch?v=odpjk7_tGY0 ( 고려대 최윤제 (1시간만에 GAN 완전 정복하기))" }, { "title": "[Graph 그래프] 그래프 전파모형", "url": "/posts/Graph-%EA%B7%B8%EB%9E%98%ED%94%84-%EA%B7%B8%EB%9E%98%ED%94%84%EC%A0%84%ED%8C%8C%EB%AA%A8%ED%98%95/", "categories": "웹, 그래프, Graph, WEB", "tags": "graph, 그래프, web, 그래프 전파모형", "date": "2021-12-17 00:00:00 +0900", "snippet": "전파모형과 전파 최대화목표 그래프를 통한 정보의 전파에 대해 나타낼 수 있음 수학적 모형화를 통한 전파 과정에 대해 설명 두가지 전파 모형이 존재 의사결정 기반 확률적 전파기반 의사결정 기반의 전파모형 언제 의사결정 기반의 전파모형을 사용할까? 라인 vs 카카오톡 의사결정 기반의 전파 모형의 대표적 예시, 선형 임계치 모형전파모형이 필요한 이유 주변 사람들의 의사결정이 본인의 의사결정에 영향을 미친다. 주변 사람들의 의사결정을 고려하여 각자 의사결정을 내리는 경우에 의사결정 기반의 전파 모형을 사용한다.선형 임계치 모형(Linear Threshold Model) $p$ 는 A를 선택할 확률 $p &amp;gt; q$ 일때, A를 선택 각 정점은 이웃 중 𝐴를 선택한 비율이 임계치 𝑞를 넘을 때만 𝐴를 선택한다. 본 모델에는 새로운 기술(A라 칭함)을 사용하는 사람 2명(u,v)을 가정한다. 시드 집합(Seed set)이라 불리는 얼리 어답터들은 A를 고수한다. 임계치는 55%로 설정하였다.결론 A와의 연결이 우세하다는 결론이 나는 정점은 모두 A로 바뀌었다.확률적 전파 모형 (Independent Cascade Model) 언제 사용하는가? 코로나의 전파 과정을 생각해보자. 그 누가 코로나에 걸리고 싶어 걸리는가? 이런 상황에는 ‘확률적’ 전파가 되기 때문에 확률적 전파 모형을 사용한다. 각 간선 (u,v) 의 가중치는 u가 감염되고 v가 감염되지 않았을 때, v가 감염될 확률을 의미한다. 당연하겠지만, 각각의 감염 확률은 독립적으로 작용한다.전파모형의 진행 순서는 다음과 같다. 최초 감염된 노드를 시드 집합(Seed Set)이라 한다. 최초 감염자는 주변 노드에게 $p$확률로 병을 전파한다. 위 과정을 반복한다. 새로운 감염자가 나타나지 않는다면 종료한다. 참고할 점 감염자는 계속 감염상태로 남아있음에 유의하자. 감염자의 회복을 고려하는 경우, SIS, SIR 등의 다른 전파 모형들이 있다.전파 최대화 문제 (Influence Maximization) 바이럴 마케팅 바이럴 마케팅의 경우 효과적이기 위해서는 시작점이 굉장히 중요하다 (시작점에 따라 전파속도, 범위가 차이나기 때문) 때문에 어떠한 시드집합을 고르냐가 가장 중요한 관건이다. 이러한 경우 때문에, 전파를 최대화 하는 시드 집합을 찾는 !!!문제!!! 를 전파 최대화(Influence Maximization) 문제라 일컫는다.정점 중심적 휴리스틱 전파 최대화 문제는 굉장히 어려운 문제임이 이미 증명되었다. 때문에 까불지말고 휴리스틱 방법을 이용하자.휴리스틱 : 실험적으로는 잘 동작할 수 있지만, 이론적으로는 정확도에 대해서 어떠한 보장도 할 수 없음 즉, 시드 집합의 크기가 k개로 고정되어 있을 때, 정점의 중심성이 높은 순으로 k개 정점 선택하는 방법이다 정점의 중심성을 측정하는 방법에는 페이지랭크 점수, 연결 중심성, 근접 중심성, 매개 중심성 등이 있다 합리적인 방법이지만, 최고의 시드 집합을 찾는다는 보장은 없다탐욕 알고리즘 탐욕 알고리즘은 시드 집합의 원소, 즉 최초 전파자를 한번에 한 명씩 선택 한다 즉, 정점의 집합을 {1, 2, … , ∣V∣}라고 할 경우 구체적인 단계는 다음과 같다집합 {1},{2}, … ,{∣V∣}를 비교하여, 전파를 최대화하는 시드 집합을 찾는다 이 때, 전파의 크기를 비교하기 위해 시뮬레이션을 반복하여 평균 값을 사용한다뽑힌 집합을 {x} 라고 하자 집합 {x, 1},{x, 2}, … ,{x, ∣V∣}를 비교하여, 전파를 최대화하는 시드 집합을 찾는다뽑힌 집합을 {x,y} 라고 하자= 집합 {x,y, 1},{x,y, 2}, … ,{x,y, ∣V∣}를 비교하여, 전파를 최대화하는 시드 집합을 찾는다 뽑힌 집합을 {x,y,z} 라고 하자 위 과정을 목표하는 크기의 시드 집합에 도달할 때까지 반복 한다 즉, 탐욕 알고리즘은 최초 전파자 간의 조합의 효과를 고려하지 않고 근시안적으로 최초 전파자를 선택하는 과정을 반복한다 탐욕 알고리즘은 얼마나 정확한가? 독립 전파 모형에 탐욕 알고리즘을 사용할 경우, 이론적으로 정확도가 일부 보장된다 항상, 즉 입력 그래프와 무관하게 다음 부등식이 성립한다 탐욕 알고리즘으로 찾은 시드 집합의 의한 전파의 (평균) 크기 $≥ (1− e1)×$ 최고의 시드 집합에 의한 전파의(평균) 크기 $≈0.632×$ 최고의 시드 집합에 의한 전파의 (평균) 크기 즉, 탐욕 알고리즘으로 시드 집합의 평균 전파 크기가 최고의 시드 집합에 의한 평균 전파 크기보다 적어도 0.632배 된다는것이 수학적으로 증명되있다 다시 말해, 탐욕 알고리즘의 최저 성능은 수학적으로 보장되어 있다 " }, { "title": "[WEB 웹] Page-Rank", "url": "/posts/ML-%EA%B7%B8%EB%9E%98%ED%94%84-page-rank/", "categories": "웹, 그래프, Graph, WEB, PAGE-RANK", "tags": "graph, 그래프, web, page-rank", "date": "2021-12-16 00:00:00 +0900", "snippet": "Page Rank검색엔진에서의 그래프 사용에 관함웹과 그래프 웹은 웹페이지와 하이퍼링크로 구성된 거대한 방항성 있는 그래프라고 볼 수 있다. 웹 페이지는 정점이다. 웹페이가 포함하는 하이퍼링크는 해당 웹페이지에서 나가는 간선에 해당한다. 단, 웹페이지는 추가적으로 키워드 정보를 포함하고 있다. 페이지 랭크의 출현의 이유기존의 검색엔진 방식 웹을 디렉토리(directory)로 정리함. 카테고리와 그 수가 너무 깊어짐. 카테고리 구분이 모호하다. 키워드에 의존한 검색엔진 사용자가 입력한 키워드에 대해, 해당 키워드를 (여러 번) 포함한 웹페이지를 반환. 악의적인 웹페이지에 취약. 페이지랭크따라서, 사용자 키워드와 관련성이 높고 신뢰할 수 있는 웹페이지를 찾기위한 방법으로 고안됌페이지 랭크 정의두가지 관점이 존재한다. 투표 관점 임의보행 관점1. 투표관점 투표를 통하여 사용자의 키워드와 관련성이 높고 신뢰할 수 있는 웹페이지를 찾는다. 투표 주체 : 웹페이지 투표 방법 : 하이퍼링크를 통하여 투표 어떤 웹페이지가 하이퍼링크를 포함할 때, 하이퍼링크에 걸린 웹페이지를 신뢰한다는 것을 의미 하이퍼링크에 연결된 웹페이지에 한 표를 투표한다고 생각하자. 해석방법 들어오는 간선의 수가 많다 ? -&amp;gt; 신뢰도가 높다는 뜻문제점 들어오는 간선의 수를 세는것이 악용될 소지가 있음. 웹페이지를 인위적으로 많이 만들어 들어오는 간선의 수 조작이 가능하다.해결책 약용 효과를 줄이기 위하여, 페이지랭크는 가중 투표를 한다. 즉, 관련성이 높고 신뢰할 수 있는 웹사이트의 투표를 더 중요하게 간주한다. 반면, 그렇지 않은 웹사이트들의 투표는 덜 중요하게 간주한다. 악용이 없는 경우에도 사용할 수 있는 합리적인 투표 방법이다. → 좀 더 믿을만한 웹페이지의 가중치를 더 높게 측정하는 것이다.투표 관점 간단한 식 정리 측정하려는 웹페이지의 관련성 및 신뢰도를 페이지랭크 점수라고 부르자. 각 웹페이지는 각각의 나가는 이웃에게 자신의 페이지랭크 점수 만큼의 가중치로 투표를 한다. (자신의 페이지랭크 점수)/(나가는 이웃의 수) 만큼의 가중치로 투표한다. 각 웹페이지의 페이지랭크 점수는 (이웃들에 의해) 받은 투표의 가중치 합으로 정의된다.2. 임의 보행 관점 페이지랭크는 임의 보행(Random Walk)의 관점에서도 정의할 수 있다. 임의 보행을 통해 웹을 서핑하는 웹서퍼를 가정하자. 즉, 웹서퍼는 현재 웹페이지에 있는 하이퍼링크 중 하나를 균일한 확률로 클릭하는 방식으로 웹을 서핑한다. 웹서퍼가 𝑡번째 방문한 웹페이지가 웹페이지 $i$일 확률을 $p_i (t)$ 라고 하자. 그러면 𝒑(𝒕)는 길이가 웹페이지 수와 같은 확률분포 벡터가 된다. 그러면 아래 식이 성립한다. $p(t)$는 벡터가 되고, v개의 p값이 존재한다. $p_i (t)$ 는 $i -&amp;gt; j$ 확률을 $j$에 들어오는 각각에 계산. $p_i (t+1)$ 는 $t+1$번 째 방문한 웹페이지가 $j$일 확률 $p(t) = p(t+1) = p$가 수렴한다는 것은 $t$가 충분히 커서, 각각 $p_i,p_j$가 된다.페이지 랭크 점수페이지랭크의 계산 : 반복곱 문제점 반복곱이 항상 수렴함을 보장 할 수 없음. 들어오는 간선은 있지만 나가는 간선이 없는 정점 집합인 스파이더 트랩인 경우 반복곱이 합리적인 점수로 수렴하는 것을 보장할 수 없다. 들어오는 간선은 있지만 나가는 간선은 없는 막다른 정점(Dead End)에 의한 문제 페이지랭크 점수가 0에 수렴할 수 있음 해결책 순간이동 결과 가장 투표를 많이받은 정점은 신뢰할 수 있는 정점이 되므로, 신뢰할 수 있는 정점이 가리키는 C라는 정점에 대한 신뢰도도 높아지는 것을 볼 수 있다. " }, { "title": "[React] 는 사용자가 Key를 지정해줘야 하는 이유", "url": "/posts/React-%EB%8A%94-%EC%82%AC%EC%9A%A9%EC%9E%90%EA%B0%80-Key-%EB%A5%BC-%EC%A7%80%EC%A0%95%ED%95%B4%EC%A4%98%EC%95%BC-%ED%95%98%EB%8A%94-%EC%9D%B4%EC%9C%A0/", "categories": "FrontEnd, React", "tags": "React, 리액트, React_key, 리액트 키 지정", "date": "2021-12-16 00:00:00 +0900", "snippet": "예제 코드const mapPostToElement = (arr) =&amp;gt; { return arr.map((post, index) =&amp;gt; { return( &amp;lt;div key={post.id} &amp;lt;p&amp;gt;{post.title}&amp;lt;/p&amp;gt; &amp;lt;p&amp;gt;{post.content}&amp;lt;/p&amp;gt; &amp;lt;/div&amp;gt; ) })}key 값은 뭘까?mapping하는 부분을 보면 key 속성을 볼 수가 있다. 배열의 각 요소마다 고유한 key값을 지정해 주는 속성인데 만약 key값을 생략한다면 어떻게될까?아무 이상없이 랜더링은 되지만, React는 아래와 같은 경고를 띄운다. Each child in an array should have a unique “key” prop.그럼 key값은 언제 필요한 것일까?요소의 변화를 알아차리기 위해 필요하다리액트 공식문서를 보면, key는 어떤 아이템이 변화되거나, 추가, 삭제되었는지를 알아차리기 위해 필요하다고 말한다.리액트는 state에서 변경사항이 있는 부분만 캐치해서 리랜더링 해준다. 리액트 유저라면 알고겠지만, 굳이 변경이 없는 데이터까지 Dom을 조작해서 불필요한 자원을 낭비하지 않겠다는 것이다. 그렇다면 state의 배열에 어떠한 요소가 추가가 된다고 가정해보자. 배열에 어떤 요소를 추가했으니 배열이 변경된 것이라고 생각할 수 있는데, 과연 react는 배열 전체를 리랜더링 할까? 아니면 배열에 추가된 요소 한가지만 다시 리랜더링 할까?리액트는 참 똑똑하게 배열에 추가된 딱 한가지 요소만 리랜더링한다. 다만, 배열의 key값을 고유하게 넘겨주었을 때만.즉 사용자가 직접 key 값을 지정하여, 이 값이 변경될 시 변경된 부분만 리랜더링 하라! 를 명시할 수 있도록 리액트는 기회를 주는 것이다. 말 그대로 ‘기회’ 이기 때문에 사용하지 않아도 문제는 없지만, key값을 사용하지 않는다면 react를 잘 사용한다고 볼 수 없다." }, { "title": "[React] React_Lifestyle", "url": "/posts/React-React-Lifestyle/", "categories": "FrontEnd, React", "tags": "React, React_lifestyle, 리액트 라이프 스타일", "date": "2021-12-15 00:00:00 +0900", "snippet": "React의 LifeStyle 리액트가 모든 요소들을 View 로 갖기 때문에 이 View를 데이터의 단방향으로 보장을 하면서 클래스 내애서 단일적으로 관리하기 위한 로직을 마련하는 기능을 일컫는다.리액트는 모든것이 View 로만 작동한다. 즉 Render를 기점으로 클래스를 작성해주면 된다.class LifeCycle extends React.Component{ //this.state 는 어디서 사용이 가능한가? // render 함수, unmount 함수에서 불가능하다. // 랜더링 과정중 setState 함수를 호출하는것은 말이 되지 않는다. // unmount도 마찬가지로 삭제하는 과정에서 setState를 하는 의미가 없다. constructor(props){ super(props) } componentWillMount(){ // 컴포넌트가 랜더링 되어지기 전 ! } render(){ return(&amp;lt;&amp;gt;&amp;lt;/&amp;gt;) } componentDidMount(){ // 클래스가 실행이되었을대, 랜더링 되었을때 딱 한번 실행! } componentWillUnmount(){ // 모든 로직이 완료되었을 때, 해당 컴포넌트를 삭제 or 초기화 할때. } // ... 이외에도 굉장히 많다. 자세한 내용은 React 홈페이지를 참조하길 바란다.}export default LifeCycle;" }, { "title": "[ML 머신러닝] 실제 그래프의 특성", "url": "/posts/ML-%EA%B7%B8%EB%9E%98%ED%94%84-%EC%8B%A4%EC%A0%9C%EA%B7%B8%EB%9E%98%ED%94%84/", "categories": "ML, 그래프, Graph", "tags": "머신러닝, 딥러닝, ml, graph, 그래프", "date": "2021-12-15 00:00:00 +0900", "snippet": "실제 그래프의 구조적 효과 작은 세상 효과 연결성의 두터운-꼬리 분포 거대 연결 요소 군집 구조실제그래프 vs 랜덤 그래프 실제그래프(Real Graph): 다양한 복잡계로 부터 얻어진 그래프 예시: 소셜 네트워크, 전자상거래 구매 내역, 인터넷, 웹, 뇌, 단백질 상호작용, 지식 그래프 등 (정점: 사용자, 간선: 주고받은 메시지)로 정의할 수 있다. 랜덤 그래프(Random Graph): 확률적 과정을 통해 생성한 그래프 여기서는 가장 기초적인, 에르되스-레니 랜덤 그래프(Erdős-Rényi Random Graph) 사용 [랜덤 그래프] 에르뇌스-레니 랜덤그래프 $G(n,p)$ 정의: 임의의 두 정점 사이에 간선이 존재하는지 여부는 동일한 확률 분포에 의해 결정된다. 𝑛개의 정점을 가진다. 임의의 두 개의 정점 사이에 간선이 존재할 확률은 𝑝 이다. 정점 간의 연결은 서로 독립적(Independent)이다. Q. $G(3,0.3)$ 에 의해 생성 될 수 있는 각각의 확률은?출처 : ganta.log작은 세상 효과(Small-world Effect) 필수 개념: 경로, 거리 및 지름 실제 그래프의 두 정점 사이의 거리는 작다. 적은 단계만 거치면, 많은 사람들과 연결될 수 있음을 의미한다. 실험: 여섯 단계 분리(Six Degrees of Separataion) 실험 속담: “사돈의 팔촌” - 아무리 먼 관계도 결국은 사돈의 팔촌(10촌 관계) 랜덤 그래프에서의 작은 세상 효과? 작은 세상 효과는 높은 확률로 랜덤 그래프에도 존재한다. 모든 사람이 100명의 지인이 있다고 가정해보면, 다섯 단계를 거치면 최대 100억(= 1005)명의 사람과 연결될 수 있다. 단, 실제로는 지인의 중복 때문에 100억 명보다는 적은 사람일 겁니다 하지만 여전히 많은 사람과 연결될 가능성이 높다. 체인(Chain), 사이클(Cycle), 격자(Grid) 그래프에서는 작은 세상 효과가 존재하지 않는다. 경로(path) 정점 u와 v의 사이의 경로(path)는 다음과 같은 조건을 만족하는 정점들의 순열(Sequence)이다. ✔️ u에서 시작해서 v에서 끝나야 한다. ✔️ 순열에서 연속된 정점은 간선으로 연결되어 있어야 한다. 길이 경로의 길이는 해당 경로 상에 놓이는 간선의 수로 정의 거리(Distance) 정점 u와 v의 사이의 거리(Distance)는 u와 v사이의 최단 경로의 길이이다. 지름(Diameter) 그래프의 지름(Diameter)은 정점 쌍의 거리 간 최댓값이다. 출처 : ganta.log연결성의 두터운 꼬리 분포 vs 랜덤 분포출처 : ganta.log 필수 개념 : 연결성 실제 그래프의 연결성 분포는 두터운 꼬리(heavy tail)을 가진다. 즉, 연결성이 매우 높은 허브 정점이 존재함을 의미한다. 연결성이 낮은 정점은 많으나, 연결성이 큰 노드의 수는 적다. 랜덤 그래프는 높은 확률로 정규분포와 유사하다. 연결성이 매우 높은 허브(hub)가 존재할 확률은 0에 가깝다. 정규 분포와 유사한 예시로는 키의 분포가 있다. 키가 10미터를 넘는 극단적 예시는 존재하지 않는다.거대 연결 요소 (Giant Connected Component) 필수 개념 : 연결 요소 거대 연결 요소는 대다수의 정점을 포함한다. 실제 그래프에서는 대다수의 정점을 포함하는 거대 연결 요소, 거대 그룹이 존재함. 랜덤 그래프는 높은 확률로 거대 연결 요소(Giant Connected Component)가 존재한다.이때, 정점들의 평균 연결성이 1 보다 충분히 커야 한다.(p∗(n−1)=1)직관적으로 생각 해 보면 간선이 하나 있어야 연결요소가 생기는데 p∗(n−1)은 (n−1)을 간선의 수로 본다면 간선이 생기는 수로 써 볼 수 있다. 따라서, 이 값이 1이 넘어야 급격하게 연결 요소가 생긴다고 생각 할 수 있다.군집 구조군집군집이란 다음 조건들을 만족하는 정점들의 집합. 집합에 속하는 정점 사이에는 많은 간선이 존재. 집합에 속하는 정점과 그렇지 않은 정점 사이에는 적은 수의 간선이 존재.지역적 군집 계수지역적 군집 계수(Local Clustering Coefficient)는 한 정점에서 군집의 형성 정도를 측정한다.정점 $i$ 의 지역적 군집 계수는 정점 i의 이웃 쌍 중 간선으로 직접 연결된 것의 비율을 말한다.정점 $i$ 의 지역적 군집 계수를 $C_i$ 로 표현 할 시 예시는 다음과 같다.예시) Q.지역적 군집 계수가 군집이랑 어떻게 연결되는가? 정점 𝑖의 지역적 군집 계수가 매우 높다고 하자. 즉, 정점 𝑖의 이웃들도 높은 확률로 서로 간선으로 연결되어 있다. 정점 𝑖와 그 이웃들은 높은 확률로 군집을 형성한다.전역 군집 계수 전체 그래프에서 군집의 형성 정도를 측정 그래프 $G$의 전역 군집 계수는 각 정점에서 지역적 군집 계수의 평균이다. 단, 지역적 군집 계수가 정의되지 않는 정점은 제외한다.출처 : ganta.log균일 그래프 : 군집계수 - 크다, 지름 - 크다 작은 세상 그래프 : 군집계수 - 크다, 지름 - 작다 랜덤 그래프 : 군집계수 - 작다, 지름 - 작다 " }, { "title": "[ML 머신러닝] 그래프 기초", "url": "/posts/ML-%EA%B7%B8%EB%9E%98%ED%94%84-%EA%B7%B8%EB%9E%98%ED%94%84/", "categories": "ML, 그래프, Graph", "tags": "머신러닝, 딥러닝, ml, graph, 그래프", "date": "2021-12-15 00:00:00 +0900", "snippet": "그래프의 기초1. 그래프 구성 그래프: 정점 집합과 간선 집합으로 이루어진 수학적 구조 (=네트워크) 정점: vertex, node 간선: edge, link필수 기초 지식 하나의 간선은 두 개의 정점을 연결한다. 모든 정점 쌍이 반드시 간선으로 직접 연결되는 것은 아니다. 그래프(Graph)는 정점 집합과 간선 집합으로 이루어진 수학적 구조이다. 보통 정점들의 집합을 𝑽, 간선들의 집합을 𝑬, 그래프를 𝑮 = (𝑽, 𝑬)로 적는다.그래프의 이웃 정점의 이웃(Neighbor)은 그 정점과 연결된 다른 정점을 의미한다. 정점 𝑣의 이웃들의 집합을 보통 𝑵(𝒗) 혹은 𝑵𝒗로 적는다. 나가는 이웃, 들어오는 이웃 방향성이 있는 그래프에서는 나가는 이웃과 들어오는 이웃을 구분한다. 정점 𝑣로 간선이 들어오는 이웃(In-Neighbor)의 집합을 보통 𝑵in(𝒗)로 적는다. 정점 𝑣에서 간선이 나가는 이웃(Out-Neighbor)의 집합을 보통 𝑵out(𝒗)로 적는다. 그래프를 다루기 위해 파이썬 라이브러리인 NetworkX를 사용하면 편리하다.2. 그래프가 중요한 이유? 우리 사회는 많은 복잡계(Complex System)으로 이루어져 있다. 그래프와 복잡계는 둘 다, 구성요소 간의 복잡한 상호작용이다. 따라서 복잡계를 그래프로 표현할 수 있다. 그래프는 복잡계를 표현하고 분석하기 위한 언어 복잡계는 구성 요소들 간의 상호작용으로 이루어진다. 상호작용을 표현하기 위한 수단으로 그래프가 널리 사용된다. 복잡계를 이해하고, 복잡계에 대한 정확한 예측을 하기 위해서는 복잡계 이면에 있는 그래프에 대한 이해가 반드시 필요!3. 그래프 관련 인공지능 문제 정점 분류(Node Classification) 문제 각 정점의 유형을 추측할 수 있다. 같은 유형의 노드는 같은 색을 띈다. 어떤 유형인지 모르는 노드가 주어졌을 때, 이어지는 노드의 유형을 통해, 새로 들어온 노드의 유형을 추측할 수 있다. 예시 트위터에서의 공유(Retweet) 관계를 분석하여, 각 사용자의 정치적 성향을 알 수 있을까?단백질의 상호작용을 분석하여 단백질의 역할을 알아낼 수 있을까? 연결 예측(Link Prediction) 문제 거시적 관점: 주어진 그래프가 어떻게 성장할 지 예측한다. 미시적 관점: 각 정점이 앞으로 어떤 정점과 연결될 지 예측한다. 예시: 페이스북 소셜네트워크는 어떻게 진화할까? 추천(Recommendation) 문제 기존에 주어진 구매 정보를 기반으로 예측하여 추천해준다. 예시: 각자에게 필요한 물건은 무엇일까? 어떤 물건을 구매해야 만족도가 높을까? 군집 분석(Community Detection) 문제 군집: 서로 밀접하게 연결된 집합 군집 내의 관계는 의미있는 구조를 나타내는 경우가 많다. (기계학습 클러스터링과 유사) 연결 관계로부터 의미있는, 사회적 무리(Social Circle)을 찾아낼 수 있을까? 랭킹(Ranking) 및 정보 검색(Information Retrieval) 문제 웹(Web)이라는 거대한 그래프로부터 어떻게 중요한 웹페이지를 찾아낼 수 있을까? 정보 전파(Information Cascading) 및 바이럴 마케팅(Viral Marketing) 문제 정보는 네트워크를 통해 어떻게 전달될까? 어떻게 정보 전달을 최대화 할 수 있을까? 그래프 신경망(Graph Neural Networks)4. 그래프 유형 및 분류 방향성 간선에 방향이 없는 그래프(Undirected Graph): 대등한 관계를 표현 - 협업 관계 그래프, 페이스북 친구 그래프 간선에 방향이 있는 그래프(Directed Graph): 주체와 대상을 분리 - 인용 그래프, 트위터 팔로우 그래프 가중치 간선에 가중치가 없는 그래프(Unweighted Graph): 웹 그래프, 페이스북 친구 그래프 간선에 가중치가 있는 그래프(Weighted Graph): 전화 그래프, 유사도 그래프 노드의 종류 동종 그래프(Unpartite Graph): 단일 종류의 정점을 가짐, 단일 종류의 정점을 가집니다 - 웹 그래프, 페이스북 친구 그래프 이종 그래프(Bipartite Graph): 두 종류의 정점을 가짐, 다른 종류의 정점사이에만 간선이 연결 - 전자 상거래 구매내역(사용자, 상품), 영화 출연 그래프 (배우, 영화) " }, { "title": "[ML 머신러닝] 자연어처리", "url": "/posts/ML-%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC-NLP/", "categories": "ML, NLP", "tags": "머신러닝, 딥러닝, ml, nlp", "date": "2021-12-14 00:00:00 +0900", "snippet": "NLP? Natural Language Preocessing 인간의 언어를 이해하고 생산할 수 있도록 한, 딥러닝을 이용한 방법NLP의 분야자연어 처리 분야에서는 예전부터 NLU에 대한 연구를 많이 했었다. 최근 딥러닝 시대로 넘어오면서 NLG에 대한 연구도 활발해 지고 있다고 한다. NLG NLG + NLU NLU - Language Modeling - Article Generation - Chatbot -Summerization - Question Answering - Machine Transiation - Text Classification - POS Tagging - Sentiment Analysis - Machine Reading Comprehension - Named Entity Recognition - Sematic Parsing 좀 더 구조적으로 알아보면, 자연어 처리란(NPL)란 컴퓨터에게 사람처럼 텍스트를 이해시키는 것이 아니다. 문자 언어(written language)에 대한 통계적 구조를 만들어 처리하는 것이다. 자연어 처리에서의 딥러닝은 단어, 문장, 문단에 적용한 패턴들을 인식하는 과정이라고 생각하면 된다.NLP 트렌드 텍스트 데이터는 단어의 시퀀스라고 볼 수 있다. 그리고 각 단어는 Word2Vec, GloVe라는 기술을 통해 벡터로 표현할 수 있다. RNN-family models(LSTM, GRU)는 입력으로 단어의 벡터들의 시퀀스로 이루어져있는 NLP의 주요 taskd이다. Attention module과 Transformer model을 통해서 NLP의 성능을 전반적으로 상승시킬 수 있다. 이들은 RNN을 self-attention으로 대채하였다. 최근에 각각 다른 NLP task를 위한 커스텀 모델이 빠르게 증가하였다. 커스텀하는 방법은 어떤것이 있을까? Transformer가 소개된 이후로, 아주 큰 모델이 출시되었다. 이들은 추가적인 레이블링이 필요없는, 방대한 데이터셋을 통해 자가지도학습(Self-supervised training)을 진행한다. 예를들어, BERT, GPT-3가 있다. 이후에 모델에 전이학습(transfer learning)이 적용되어 커스텀 모델이 증가했다. 최근에 이런 모델들이 NLP에 필수가 되면서, 방대한 데이터를 학습하는 것이 필수가 되었다. 따라서 NLP 연구는 한정된 GPU 자원으로 모델을 학습하기에는 무리가 있다는 단점을 가진다." }, { "title": "[ML 머신러닝] Transformer 모델 기초", "url": "/posts/ML-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%8B%9C%ED%80%80%EC%85%9C/", "categories": "ML, Sequential Model, Transformer", "tags": "머신러닝, 딥러닝, ml, transformer", "date": "2021-12-13 00:00:00 +0900", "snippet": "TransformerSequential Model의 한계점RNN에서 다루었던 Sequential Model들은 완벽한 구성성분을 가진 특정 데이터가 아니면 학습하기가 어려웠다. 문장을 학습할 때 Origianl Sequence 나는 오늘 학교에 가서 학식을 먹었다. Trimmed Sequence - 문장마다 길이가 다르다. 나는 오늘 학교에 갔다. Omitted Sequence - 문장성분이 누락될 수 있음. 오늘 학식 먹었다. Permuted Sequence - 성분의 순서가 permute 될 수 있음. 오늘 학교 가서 먹었지, 나는 이러한 문제를 해결하기 위한 것이 Transformer 구조이다.Transformer 구조?1. Transformer 란?트랜스포머(Transformer)는 2017년 구글이 발표한 논문인 “Attention is all you need”에서 나온 모델로 기존의 seq2seq의 구조인 인코더-디코더를 따르면서도, 논문의 이름처럼 어텐션(Attention)만으로 구현한 모델입니다. 이 모델은 RNN을 사용하지 않고, 인코더-디코더 구조를 설계하였음에도 번역 성능에서도 RNN보다 우수한 성능을 보여주었습니다.2. Transformer 의 주요 하이퍼파라미터시작에 앞서 트랜스포머의 하이퍼파라미터를 정의합니다. 각 하이퍼파라미터의 의미에 대해서는 뒤에서 설명하기로하고, 여기서는 트랜스포머에는 이러한 하이퍼파라미터가 존재한다는 정도로만 이해해보겠습니다. 아래에서 정의하는 수치는 트랜스포머를 제안한 논문에서 사용한 수치로 하이퍼파라미터는 사용자가 모델 설계시 임의로 변경할 수 있는 값들입니다." }, { "title": "[ML 머신러닝] RNN", "url": "/posts/ML-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-RNN/", "categories": "ML, RNN", "tags": "머신러닝, RNN, 딥러닝, ML, Deeplearning", "date": "2021-12-12 00:00:00 +0900", "snippet": "RNNSequential Model시퀀스 데이터 순차적 데이터 사건의 발생 순서가 중요한 경우 ( 온도, 자연어, 소리, 주가.. 등) 순서를 바꾸거나 정보에 손실이 생길경우 데이터의 확률분포 또한 바뀌게 됨.Sequential Model시퀀스 데이터를 처리하는데 어려운 것은, 길이의 끝이 언제인지 모른다는 점이다. 때문에, 입력의 차원 또한 알 수 없다. 이를 해결하는 방법으로, 고정된 길이 ($\\tau$)의 과거정보만을 확인하는 Markov Model이 있다. 극단적으로 간단히 만든 것이 바로 직전 시점 정보만을 고려하는 AR(1) 모델이다. 기존 AR모델을 보완한것이, 과거의 정보들을 ‘기억’하는 모델을 만들었는데 그것이 바로 Latent Autoregressive Model이다.출처 : [https://velog.io/@hanlyang0522/DL-Basic-7%EA%B0%95-Sequential-Models-RNN] 이 모델은 hidden state인데, 출력값이 입력값에 그 전까지 모든 시점정보들을 요약한 값을 고려하여 만들어진다.Recurrent Neural Network맥락을 이해하고 처리하기 위해서는 이전의 결과가 다음 결과에 영향을 미칠 수 있어야 한다. 영향을 미칠 수 있어야 Series데이터 처리가 가능하다. $x_t$는 입력값 $h_t$는 출력값이다. A는 뉴럴넷 덩어리 이다. A의 결과는 다시 A로 들어가서 루프를 생성한다. 때문에, 현재의 상태(state)가 다음 상태(state)에 영향을 미치게 된다.저것을 풀어 설명한 그림이 오른쪽 그림이다.어찌되었든 핵심은 RNN의 상태(state)를 계산할때, 이전 상태(state)를 계산한다는 것이다.하지만 아직 이 모델로는 문제점이 나타난다. 바로 과거의 정보들을 미래의 정보로 끌고오는 상황이기에, 역설적으로 더 오래된(멀리있는) 정보일수록 살아남기 힘들다는 것이다. 이처럼 RNN은 이처럼 short-term dependencies는 잘 잡지만, Long-term dependencies는 잡기 어렵다는 치명적 단점이 존재한다.RNN은 과거의 $h$들을 고려하는 중첩된 구조인데, 식으로 표현하자면 다음과 같다.$$h_1 = \\phi(W^T h_0 + U^T x_1)$$$$h_2 = \\phi(W^T \\phi(W^T h_0 + U^T x_1) + U^T x_2)$$$$h_3 = \\phi(W^T \\phi(W^T \\phi(W^T h_0 + U^T x_1) + U^T x_2) + U^T x_1)$$ $\\phi$는 활성함수(activation function) 이다. 이와 같이 RNN은 여러 활성함수(input) 의 구조가 반복된다.그렇다면, 활성화함수가 sigmoid라 한다면, 함수가 중첩될수록 점점 기울기 소실의 문제가 발생할테고, 만약 솰성화함수가 ReLU라면 기울기 폭발 문제가 발생하게 될것이다.LSTM이러한 단점들을 없애기 위하여 나온 모델이 Long Short Term Memory (LSTM)이다.LSTM의 핵심은 4개의 상호작용 layer가 들어 있다는 점이다.복잡해 보이지만 생각보다 살펴보면 조금은 친근해질 수 있다.위 그림에서 각 선(line)은 한 노드의 output을 다른 노드의 input으로 vector 전체를 보내는 흐름을 나타낸다. 분홍색 동그라미는 vector 합과 같은 pointwise operation을 나타낸다. 노란색 박스는 학습된 neural network layer다. 합쳐지는 선은 concatenation을 의미하고, 갈라지는 선은 정보를 복사해서 다른 쪽으로 보내는 fork를 의미한다.Cell stateCell state가 LSTM의 핵심이라 할 수 있다.Cell state는 컨베이어 벨트와 같이, 작은 linear interaction만을 적용시켜 전체 체인을 계속 구동시킨다. 정보가 바뀌지 않고 그대로 흐르게만 할 수도, 혹은 다른 Gate를 통해 정보 제어하여 흘려보낼 수도 있다.자세한 내용은 링크 를 클릭하여 알아보도록 하자. 각 게이트와 구조의 흐름을 굉장히 잘 설명해놓은 블로그이다.GRU기존의 RSTM의 복잡한 구조 때문에, 조금 더 단순한 구조로 제안된 모델이다. Gated Recurrent Unit (GRU)의 약자로, 게이트가 3개 있던 LSTM과 달리 2개의 게이트(reset, update)만을 가진다. 또 cell state가 없으며, hidden state만을 가진다.Reset Gate 가 기존의 Forget Gate 역할을 하고, Input&amp;amp;Output Gate 가 합쳐져 Update Gate 역할을 한다고 볼 수 있다.파라미터 개수가 LSTM보다 적음에도 불구하고 비슷한 작용을 하므로, 대체로 일반화 성능이 좋은 편이다.그러나 최근에는 LSTM과 GRU 모두 Transformer가 나오면서 대체되고 있는 추세다.참고 욕심많은 알파카 개발새발로그" }, { "title": "[ML] Modern CNN", "url": "/posts/ML-Modern-CNN/", "categories": "ML, CNN", "tags": "머신러닝, CNN, 딥러닝, ML, Deeplearning", "date": "2021-12-11 00:00:00 +0900", "snippet": "Convolutional Neural Networks (CNN) 대표적 CNN 모델들에 대해 알아본다. (매 대회에서 1등했던 모델들) AlexNet 최초로 Deep Learning을 이용하여 ILSVRC에서 수상 VGGNet 3x3 Convolution을 이용하여 Receptive field는 유지하면서 더 깊은 네트워크를 구성 GoogLeNet Inception blocks 을 제안 ResNet Residual connection(Skip connection)이라는 구조를 제안 DenseNet Resnet과 비슷한 아이디어지만 Addition이 아닌 Concatenation을 적용한 CNN AlexNet 네트워크가 두개로 구성 이유: 당시 GPU 부족 ➡ 네트워크에 최대한 많은 파라미터를 넣고자 input: 11 x 11 ➡ 그렇게 좋은 선택은 아님 receptive field 하나의 convolutional kernel이 볼 수 있는 이미지 레벨 영역은 커짐 그러나 상대적으로 더 많은 파라미터 필요 총 depth: 8단 Key Ideas Rectified Linear Unit(ReLU) Activation GPU implementation(2GPUs) Data Augmentation Dropout: 뉴런 중에서 몇개를 0으로 만듦 Local response normalization Overlapping pooling 초록색 : 현재에 많이 사용하는 기법들.Relu ReLu는 Rectified Linear Unit의 약자로 해석해보면 정류한 선형 유닛이라고 해석할 수 있다. ReLu를 Activation function이 발표된지는 오래되었다. 그러나 현재처럼 Neural Network에서 주된 activation function으로 사용된지는 오래되지 않았다. Neural Network를 처음배울 때 activation function으로 sigmoid function을 사용한다. sigmoid function이 연속이여서 미분가능한점과 0과 1사이의 값을 가진다는 점 그리고 0에서 1로 변하는 점이 가파르기 때문에 사용해왔다. 그러나 기존에 사용하던 Simgoid fucntion을 ReLu가 대체하게 된 이유 중 가장 큰 것이 Gradient Vanishing 문제이다. Simgoid function은 0에서 1사이의 값을 가지는데 gradient descent를 사용해 Backpropagation 수행시 layer를 지나면서 gradient를 계속 곱하므로 gradient는 0으로 수렴하게 된다. 따라서 layer가 많아지면 잘 작동하지 않게 된다. 따라서 이러한 문제를 해결하기위해 ReLu를 새로운 activation function을 사용한다. ReLu는 입력값이 0보다 작으면 0이고 0보다 크면 입력값 그대로를 내보낸다.출처: https://mongxmongx2.tistory.com/25 [몽이몽이몽몽이의 블로그]VGGNet Increasing depth with 3 x 3 convolution filters (with stride 1) 3 x 3 convolution filters ➡ 이것만 사용! 1 x 1 convolution for fully connected layers 채널을 줄이기 위해서 사용된 것이 아니므로, 별로 중요하지는 않음 Dropout (p=0.5) VGG16, VGG193x3 의 convolution filters 만 사용하였다 필터의 사이즈가 3x3 으로 고정된 이유 ? -&amp;gt; 발표한 논문에 의하면 연산하여 발생하는 파라미터 수가 줄어들고 ReLU 가 활성화 함수로 들어갈 수 있는 곳이 많아진다는 장점이 존재한다. 파라미터의 수가 차이나는 이유는? 3 x 3 x 2 = 18 &amp;lt; 5 x 5 = 25 즉 필터를 작게 쓸 경우 레이어를 두개 두더라도 파라미터 수가 더 작은 효과를 볼 수 있음. Google NetGoogleNet 의 구조도 [출처 : Google 논문]구글넷은 22개의 층으로 구성되어 있다. 이젠 구글넷의 특징을 알아보자.1. 1x1 컨볼루션구조도를 보면 알겠지만, 곳곳에 1x1 컨볼루션이 존재함을 알 수 있다.1x1 컨볼루션이 가지는 의미는 무엇일까? -&amp;gt; 특성맵의 갯수를 줄이는 목적으로 사용된다. 특정맵의 갯수가 줄어들면 그만큼 연산량이 줄어든다.예를 들어, 480장의 14 x 14 사이즈의 특성맵(14 x 14 x 480)이 있다고 가정해보자. 이것을 48개의 5 x 5 x 480의 필터커널로 컨볼루션을 해주면 48장의 14 x 14의 특성맵(14 x 14 x 48)이 생성된다. (zero padding을 2로, 컨볼루션 보폭은 1로 설정했다고 가정했다.) 이때 필요한 연산횟수는 얼마나 될까? 바로 (14 x 14 x 48) x (5 x 5 x 480) = 약 112.9M이 된다.이번에는 480장의 14 x 14 특성맵(14 x 14 x 480)을 먼저 16개의 1 x 1 x 480의 필터커널로 컨볼루션을 해줘 특성맵의 갯수를 줄여보자. 결과적으로 16장의 14 x 14의 특성맵(14 x 14 x 16)이 생성된다. 480장의 특성맵이 16장의 특성맵으로 줄어든 것에 주목하자. 이 14 x 14 x 16 특성맵을 48개의 5 x 5 x 16의 필터커널로 컨볼루션을 해주면 48장의 14 x 14의 특성맵(14 x 14 x 48)이 생성된다. 위에서 1 x 1 컨볼루션이 없을 때와 결과적으로 산출된 특성맵의 크기와 깊이는 같다는 것을 확인하자. 그럼 이때 필요한 연산횟수는 얼마일까? (14 x 14 x 16)(1 x 1 x 480) + (14 x 14 x 48)(5 x 5 x 16) = 약 5.3M이다. 112.9M에 비해 훨씬 더 적은 연산량을 가짐을 확인할 수 있다. 연산량을 줄일 수 있다는 점은 네트워크를 더 깊이 만들수 있게 도와준다는 점에서 중요하다.출처 : [https://bskyvision.com/539] 2. Inception module이번에는 GoogleNet 의 핵심인 Inception 모듈에 대해 알아보자.출처 : [https://bskyvision.com/539]GoogleNet은 이전 층에서 생성된 특성맵을 1x1, 3x3, 5x5, 3x3 max pooling 의 결과로 얻은 특성맵들을 하나로 합쳐주며 쌓아준다. 이 결과는 좀 더 다양한 종류의 특성이 도출되는 효과를 가진다. 여기에 1x1 컨볼루션과 함께해 당연히 연산량은 더더욱 줄어든다.ResNetResNet은 residual repesentation 함수를 학습함으로써 신경망이 152 layer까지 가질 수 있다. ResNet은 이전 layer의 입력을 다음 layer로 전달하기 위해 skip connection(또는 shorcut connection)을 사용한다. 이 skip connection은 깊은 신경망이 가능하게 하고 ResNet은 ILSVRC 2015 우승을 했다.보통의 경우 신경망이 깊어질 경우 더 정확한 예측을 할거라고 예상하지만, 신경망이 깊을 때, 작은 미분값이 여러번 곱해지면 0에 가까워 지고 큰 미분값이 여러번 곱해지면 값이 매우 커지게 된다. 즉 기울기 소실, 기울기 폭발 현상이 일어날 수 있다.출처 : ResNet 논문Skip / Shortcut Connection in Residual Network (ResNet) 따라서 위와 같은 문제를 해결하기 위하여 입력 x의 값을 몇번의 layer 이후에 출력값에 더해주는 skit/shortcut connection 이 나오게 된다.출처 : ResNet 논문기존의 신경망은 H(x) = x가 되도록 학습 했다. skip connection에 의해 출력값에 x를 더하고 H(x) = F(x) + x로 정의한다. 그리고 F(x) = 0이 되도록 학습하여 H(x) = 0 + x가 되도록 한다. 이 방법이 최적화하기 훨씬 쉽다고 한다. 미분을 했을 때 더해진 x가 1이 되어 기울기 소실 문제가 해결된다.기울기 소실 문제가 해결되면 정확도가 감소되지 않고 신경망의 layer를 깊게 쌓을 수 있어 더 나은 성능의 신경망을 구축할 수 있다!.DenseNet출처 : DenseNet 논문Dense ConnectivityDenseNet 은 모든 레이어의 피쳐맵을 연결한다. 이전 레이어의 피쳐맵을 그 이후의 모든 레이어에 연결한다.하지만 여기서 차이점이 있다. ResNet과 달리 연결할때, 덧셈이 아닌 concatenate(사슬처럼 잇다)를 수행한다. 때문에 연결할 때, 피쳐맵의 크기가 동일해야한다는 점도 작용한다. 이로인해 얻는 장점은? Strong gradient flow, information flow : 기존의 CNN 모델은 많은 레이어를 통과할 경우, 처음 레이어의 피쳐맵에 대한 정보가 끝에 다다라서 사라지지만 DensNet의 경우 정보가 소실되지 않는다. 파라미터수와 연산량이 적다 : DenseNet은 적은 채널수를 이용하기 때문에, 적은 채널 수의 피쳐맵을 생성한다. 그리고 이 피쳐맵이 이전 레이어의 피쳐맵과 결합하여 다음 레이어에 전달된다. Dense BlockConcatenation 을 수행하기 위해서는, 피채맵의 크기가 동일해야 하지만, 피쳐맵의 크기를 감소시키는 Pooling 연산 또한 CNN에서 필수적인 요소이다.따라서 이를 해결하기 위해, Dense Block 을 수행한다.출처 : DenseNet 논문 transition layer ( 그림상에서 convolution , pooling ) 피쳐맵의 크기와 채널을 줄인다. 차원 축소의 개념. Dense Block 피쳐맵의 크기와 채널이 늘어난다. 채널의 수가 기하급수적으로 증가한다. " }, { "title": "[ML] Math_AI 확률론", "url": "/posts/ML-Math_-AI-%ED%99%95%EB%A5%A0%EB%A1%A0/", "categories": "ML, 확률론", "tags": "머신러닝, 확률론, 딥러닝, ML, Deeplearning", "date": "2021-12-10 00:00:00 +0900", "snippet": "[ML] 확률론딥러닝에서 확률론에 대해 공부해야 하는 이유 기계학습에서 손실함수의 작동원리는 데이터 공간을 통게학적으로 해석해서 유도함. 예측이 틀릴 위험(risk)을 최소화하도록 데이터를 학습하는 원리는 통계적 기계학습의 기본원리 회귀분석에서 손실함수로 사용되는 $L_2$-norm 은 예측오차의 분산을 가장 최소화 하는 방향으로 학습하도록 유도 분류문제에서 사용되는 교차엔트로피(cross-entropy) 는 모델예측의 불확실성을 최소화하는 방향으로 학습하도록 유도 분산 및 불확실성을 최소화하기 위해서는 측정하는 방법을 알아야함 두 대상을 측정하는 방법을 통계학에서 제공하기 때문에 기계학습을 이해하려면 확률론의 기본개념을 알아야함 확률 분포 데이터공간 : $x\\times y$ 데이터 공간에서 데이터를 추출하는 분포 : 데이터는 확률변수 : $(x,y)$~$D$ 결합분포 $P(x,y)$ 는 $D$ 를 모델링한다. 조건부확률 $P(x|y)$ 는 데이터 공간에서 입력 $x$ 와 출력 $y$ 사이의 관계를 모델링한다이산확률분포 vs 연속확률변수 확률변수는 확률분포 $D$ 에 따라 이산형 discrete 과 연속형 continuous 확률변수로 구분하게 된다. 이산형 확률변수는 확률변수 가 가질 수 있는 경우의 수를 모두 고려하여 확률을 더해서 모델링한다.$$P(X\\in A) = \\displaystyle\\sum_{X\\in A}{P(X \\in x)}$$ 연속형 확률변수는 데이터 공간에 정의된 확률변수의 밀도 위에서의 적분을 통해 모델링한다. 밀도는 누적 확률분포의 변화율을 모델링한다 $$P(X \\in A) = \\displaystyle\\int_{A}{P(x)dx} $$조건부확률과 기계학습 조건부확률 $P(y\\mid x)$ 는 입력변수 $x$ 에 대해 정답이 $y$ 일 확률을 의미한다. ex 주사위를 굴려 나온 숫자가 홀수 일때 숫자가 1일 확률 분류문제에서 softmax $(W\\phi + b)$ 는 데이터 x로부터 추출된 특징패턴 $\\phi(x)$ 와 가중치 행렬 $W$을 통해 조건부확률 $P(y\\mid x)$ 를 계산한다.몬테카를로 샘플링 기계학습의 많은 문제들은 확률분포를 명시적으로 모를 때가 대부분 확률분포를 모를 때 데이터를 이용하여 기대값을 계산하려면 몬테카를로(Monte Carlo) 샘플링 방법을 사용해야 한다. 몬테카를로 기법은 연속, 이산 상관없이 성립함. 몬테카를로 샘플링은 독립 추출만 보장된다면 대수의 법칙(law of large number)에의해 수렴성을 보장몬테카를로 예제 $f(x)$의 적분값을 구하는것은 불가능에 가깝다. (구한다면 아마.. 수학과 쪽으로 가야하지 않을까?)import numpy as npdef mc_int(fun, low, high, sample_size=100, repeat=10): int_len = np.abs(high - low) stat = [] for _ in range(repeat): x = np.random.uniform(low=low, high=high, size=sample_size) fun_x = fun(x) int_val = int_len * np.mean(fun_x) stat.append(int_val) return np.mean(stat), np.std(stat)def f_x(x): return np.exp(-x**2)print(mc_int(f_x, low=-1, high=1, ssample_size=10000, repeat=100))" }, { "title": "[ML] 선형모델과 역전파", "url": "/posts/%EC%97%AD%EC%A0%84%ED%8C%8C%EC%88%9C%EC%A0%84%ED%8C%8C/", "categories": "ML, 역전파", "tags": "머신러닝, 역전파, 딥러닝, ML, Deeplearning, Back propagation", "date": "2021-11-01 00:00:00 +0900", "snippet": "딥러닝의 학습방법1. 선형모델데이터를 선형모델로 해석하여 $y$값과 선형모델 예측값 $\\hat{y}$의 차이의 $L_2-norm$의 기댓값을 최소화하는 $\\beta$를 찾는것이였다.$${min \\parallel y- \\hat{y} \\parallel}_2$$그러나 선형 모델은 단순한 선형모델을 푸는데 사용할 수 있지만, 분류(Classification)이나 더 복잡한 패턴의 문제를 제대로 예측하기가 어렵다.따라서, 비선형모델 신경망(Neural Network)를 사용해보자.신경망은 비선형모델이지만, 내부적으로는 선형모델들의 결합을 기반으로 만들어져있다.2. 신경망의 수식 표현$$ O = XW + b$$ 전체 데이터가 모인 행렬 $X$ $X$의 한 행벡터는 하나의 점으로 표현되는 데이터 포인트이다. $X$의 데이터를 출력 $O$로 보내주는 가중치 행렬 $W$ $X$의 데이터를 다른 공간으로 보내주는 역할을 한다. $y$ 절편에 해당하는 행벡터를 모든 행에 복제하여 만든 절편 행렬 $b$ 각 행들은 전부 같은 값 $[b_1,b_2,…,b_p]$ 를 가진다. 이 때, 출력벡터 차원(열)은 기존의 $X$ 벡터 차원 $D$에서 $P$로 바뀌게 된다.3. 소프트맥스(Softmax) 연산softmax 함수는 모델의 출력을 확률로 해석 할 수 있게 변환해주는 연산이다.분류 문제를 풀 때 선형모델과 소프트맥스 함수를 결합하여 예측할 수 있다.다음은 총 클래수의 수가 3개라고 하였을때, 다음과 같은 결과가 나온다.단순한 생김새는 “k번일 확률 / 전체 확률”의 생김새로 의외로 간단하다.단 소프트맥스 함수는 학습 시에만 사용하고 추론할 때는 사용하지 않는다.추록을 할 때에는 출력값에서 최댓값을 가진 주소만 1로 출력하는 one-hot vector을 사용하며, 주어진 출력 중 최댓값 주소만 가져가는 형태로 구현하기 때문이다.여기서 우리는 생각해볼 수 있다. 선형함수에 소프트맥스 함수를 적용시켜 선형 모델을 분류문제에 알맞은 확률 추측 모델로 바꾸어서 출력값을 조정할 수 있다면, 선형 함수에 다른 함수를 합성하면 비선형 문제 또한 풀리지 않을까?4. 활성함수(activation function)활성함수는 실수값을 입력으로 받아 -&amp;gt; 다시 실수값을 출력하는 비선형 함수이다. 선형모델을 입력으로 받아서 각각의 원소에 대하여 적용된다. 즉 활성함수는 벡터 $v = (v_1,v_2,…,v_i)$를 개별적으로 적용하여 새로운 벡터 $v =(f(v_1),…,f(v_i))$를 만들어낸다. 이때 이 벡터 $v$를 뉴런이라고 부른다. 이러한 뉴런의 집합체를 Neural Network라 부른다. 가장 중요한 점은, 활성함수가 없다면 딥러닝은 선형모델과 차이가 없다는 것이다.오늘날 가장 유명한 activation function은 Relu이며 다른 활성함수보다 좋은 성능을 보이고 있다.5. 딥러닝의 학습 원리5-1.역전파 알고리즘앞서 말한 신경망은 입력값 $X$를 받아 선형모델 -&amp;gt; 활성함수를 거쳐 출력하는 연산이다.이때, 가중치 $W$를 학습시키려면 가중치에 대한 gradient 벡터를 연산해야한다.이 과정을 Backpropagation 알고리즘으로 수행한다. 즉 경사하강법을 적용시킨다.이때 기본적 선형모델과 달리 층이 존재하므로, 각 층에 걸쳐 순차적으로 gradient벡터를 계산한다. (한번에 적용시킬 수 없다는 말!)사용하는 원리는 합성함수의 미분법 을 이용한다. 신경망이 3층에 걸쳐서 만들어져 있다고 하자. 이때 첫번째 신경망의 gradient는 다음과 같이 구할 수 있다.$${\\partial L \\over \\partial W_1} = {\\partial L \\over \\partial W_3} \\times{\\partial W_3 \\over \\partial W_2} \\times {\\partial W_2 \\over \\partial W_1}$$이처럼 딥러닝을 학습시킬때, 각각의 가중치 행렬에 대한 gradient벡터를 SGD에 이용하여, 데이터를 바꾸어가며(mini batch) 파라미터들을 학습 시킨다." }, { "title": "[ML] 경사하강법", "url": "/posts/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95/", "categories": "ML, 경사하강법", "tags": "머신러닝, 경사하강법, 딥러닝, ML, Deeplearning", "date": "2021-11-01 00:00:00 +0900", "snippet": "선형회귀 선형회귀 : 이루어진 데이터들 속에서 결곽값을 잘 내는 모델을 찾는 것 경사하강법 sklearn 라이브러리 회귀분석 방법도 있다. 링크 우리가 알아볼 것은 경사하강법이다!&amp;lt;/br&amp;gt;경사하강법으로 선형회귀 계수 구하기 선형회귀의 목적식 : ${\\parallel y - X_\\beta \\parallel}_2$ (= $L_2$-norm) 선형회귀의 목적식을 최소화 하는 $\\beta$를 찾는것이 목적!다음과 같은 Gradient 벡터를 구해보자.이 때 $\\beta$ 의 k번째 계수에 해당하는 $\\beta_k$를 가지고 목적식을 편미분하는 식을 풀어서 보면 아래와 같은 식이 된다.여기서 조심할 점은, 일반적인 수학의 $L_2$ - norm 과 풀이 방식이 살짝 다르다는 것.여기서 사용하는 $L_2 - norm$은 모델 학습에 사용되는 것이므로, n개의 데이터셋을 가지고 있다는 가정하에 출발한다. 따라서 단순히 $\\sum_{i=1}^{n}$에 $\\surd$을 바로 씌우는 것이 아닌, $1/n$ 로 형균을 내준 뒤에 씌어준다.이 때에 사용되는 Loss는 RMSE (Root Mean Squared Error) 이다. 다음과 같은 도출과정을 따른다. 벡터의 거리는 $L_2-norm$ 으로 계산한다. SE(Sqaured Error) 는 각 데이터별로 정답과 예측 벡터의 차이를 $L_2-norm$ 제곱으로 계산한다. MSE (Mean Squared Error) 는 SE 를 데이터의 숫자만큼 나누어준다.(평균내기) RMSE (Root Mean Squared Error) 는 MSE 에 제곱근을 취해준다.이를 계산하여 정리하면 다음과 같다.따라서 이제, 목적식을 최소화하는 $\\beta$ 를 구하는 경사하강법 알고리즘을 다음과 같이 표현할 수 있다. t를 반복적으로 계산하다 보면 목적식을 최소화하는 $\\beta$ 를 구할 수 있음 이전과정에 비해, 다변수인 것을 제외히ㅏ면 모든 요소가 같음 $\\beta^{(t)}$ : t번째 단계에서의 coefficient $\\lambda$ : 학습률 - 수렴속도 지정 $\\nabla_{\\beta}$ : gradient vector $\\lambda \\nabla_{\\beta} \\parallel y-x\\beta (t) \\parallel$ : gradient factor 선형회귀의 목적식은 L2-norm 과 같고, 경사하강법에서 L2-norm 대신 L2-norm의 제곱을 사용하는 것도 가능하다. 둘은 동일한 결과를 가져온다.경사하강법 기반 선형회귀 알고리즘# Input: X, y, lr, T# Output: beta&quot;&quot;&quot;norm: L2-norm을 계산하는 함수lr: 학습률T: 학습횟수&quot;&quot;&quot;for t in range(T): # eps로 사용가능, 지정된 시간의 종료조건 error = y - X @ beta grad = - transpose(X) @ error # @: 행렬곱 beta = beta - lr * grad위와 같은 경사하강법 알고리즘을 이용해, 무어-팬로즈 역행렬을 사용하지 않고도 계수 $\\beta$ 를 찾을 수 있다.# numpy를 활용한 경사하강법 수행 예시import numpy as npX = np.array([[1,1],[1,2],[2,2],[2,3]])y = np.dot(X, np.array([1,2])) + 3beta_gd = [10.1, 15.1, -6.5] # [1,2,3]이 정답 - 지금 값은 무작위 값# intercept항 추가# y 절편을 추가하면, y = ax + b의 b가 bias term의 역할을 해서 계산이 용이하다.X_ = np.array([np.append(x,[1]) for x in X])for t in range(5000): error = y - X_ @ beta_gd # error = error / np.linalg.norm(error) grad = - np.transpose(X_) @ error beta_gd = beta_gd - 0.01 * gradprint(beta_gd)# [1.00000367 1.99999949 2.99999516] lr 은 학습률에 관한것으로 실제로 학습에 지대한 영향을 끼친다. 학습률이 낮을 시 학습속도가 느려지며, 학습률이 크다면 불안정한 gredient 움직임이 발생한다.경사하강법이 수렴하지 않을 때 - 확률적 경사하강법이론적으로, 경사하강법은 미분가능하고 볼록(convex)한 함수에 대해서는, 적절한 학습률과 학습횟수를 선택했을 때 수렴이 보장되어있다.특히, 선형회귀 목적식 ${\\parallel y - X\\beta \\parallel}_2$ 는 회귀계수 $\\beta$ 에 대해 볼록함수 이므로, 알고리즘을 충분히 돌렸을 경우 수렴이 보장된다.그러나, 비선형회귀 문제의 경우 목적식이 볼록하지 않을 수 있으므로, 수렴이 항상 보장되지는 않는다.특히 딥러닝을 사용하는 경우는 목적식이 대부분 볼록함수가 아니므로,이 경우 일반적인 경사하강법이 아닌 확률적 경사하강법(SGD) 을 사용한다.확률적 경사하강법은 모든 데이터를 사용해서 업데이트 하는 대신에, 데이터 하나 또는 일부를 활용하여 업데이트 하는 방식이다.확률적 경사하강법의 원리 : 미니배치 연산경사하강법 (GD) 는 전체 데이터를 이용하여 목적식을 계산한다.반면 SGD는 미니배치를 가지고 계산한다. 따라서 매 step 마다 다른 미니배치를 사용할 때마다 목적식의 모양이 점점 바뀌게 된다. 즉, Local MiniMum (극소점) 을 탈출할 수 있다는 말!하지만 간과하지 말아야 할 것이 있다.극소점을 탈출할 수 있다는 말은 global minimum을 탈출할 수도 있다는 말이다. 이는 SGD의 단점 중 하나로, global minimum 근처까지는 빠르게 수렴하지만 정작 정확한 global minimum 극소값에는 도달하지 못하고 진동하는 경우가 많다. 반면, GD 는 연산량과 시간이 많이 필요하지만 전체 배치를 통해 모든 점에서 일정한 목적식을 활용하여 global minimum 으로 확실히 수렴 가능하다. 이와 같은 SGD의 문제점은 lr 을 점점 줄여나가는 방식으로 step size 를 줄임으로써 어느정도 해결할 수 있다.SGD는 볼록이 아닌 목적식에서도 사용 가능하므로 경사하강법보다 머신러닝 학습에 더 효율적이다. 다만, 경사하강법처럼 정확하게 gradient 벡터를 계산해서 흐르는것이 아니므로, 이동방향이 좀 튀는 경향 이 있다. 그렇지만, 결국 데이터를 가지고 gradient 벡터를 계산해서 움직이기 때문에 최솟점으로 향한다는 것은 같다. 또한, 미니배치를 가지고 연산하므로, 각각의 gradient 벡터 계산에 있어서 연산속도가 훨씬 빠르다.단, SGD에서는 기존의 경사하강법에서 고려했던 학습률(learning rate), 학습횟수(T)에 더해 미니배치 사이즈까지 고려하여 학습해야한다.참고한 자료 :https://blogik.netlify.app/BoostCamp/U_stage/05_gradient_descent/" } ]
