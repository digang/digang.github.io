---
layout: post
title : "[ML 머신러닝] RNN"
categories: [ML, RNN]
tags: [머신러닝, RNN , 딥러닝, ML , Deeplearning] # TAG 는 소문자로 작성할 것
use_math : true
---

# **RNN**

---

## **Sequential Model**

### **시퀀스 데이터**
- 순차적 데이터
- 사건의 발생 순서가 중요한 경우 ( 온도, 자연어, 소리, 주가.. 등)
- 순서를 바꾸거나 정보에 손실이 생길경우 데이터의 확률분포 또한 바뀌게 됨.

### **Sequential Model**

시퀀스 데이터를 처리하는데 어려운 것은, <span class="custom_underline">**길이의 끝이 언제인지 모른다는 점**</span>이다. 때문에, **입력의 차원 또한 알 수 없다.**

- 이를 해결하는 방법으로, **고정된 길이 ($\tau$)의 과거정보만을 확인**하는 `Markov Model`이 있다. 극단적으로 간단히 만든 것이 바로 직전 시점 정보만을 고려하는 `AR(1) 모델`이다.
- 기존 `AR모델`을 보완한것이, 과거의 정보들을 '기억'하는 모델을 만들었는데 그것이 바로 `Latent Autoregressive Model`이다.

![Latent](https://media.vlpt.us/images/hanlyang0522/post/34fcf2a4-1112-40b7-ab01-7b9f50f8ce56/image.png)
<center>출처 : [https://velog.io/@hanlyang0522/DL-Basic-7%EA%B0%95-Sequential-Models-RNN] </center>

이 모델은 hidden state인데, **출력값이 입력값에 그 전까지 모든 시점정보들을 요약한 값을 고려**하여 만들어진다.

## **Recurrent Neural Network**

맥락을 이해하고 처리하기 위해서는 이전의 결과가 다음 결과에 영향을 미칠 수 있어야 한다. 영향을 미칠 수 있어야 `Series`데이터 처리가 가능하다.

![RNN-model](https://miro.medium.com/max/1400/0*V5Q5gGhiDGurHd-z.png)

- $x_t$는 입력값 $h_t$는 출력값이다.
- A는 뉴럴넷 덩어리 이다.
- A의 결과는 다시 A로 들어가서 루프를 생성한다. 때문에, **현재의 상태(state)가 다음 상태(state)에 영향을 미치게 된다.**

저것을 풀어 설명한 그림이 오른쪽 그림이다.

<span class="custom_underline">**어찌되었든 핵심은 RNN의 상태(state)를 계산할때, 이전 상태(state)를 계산한다는 것이다.**</span>

하지만 아직 이 모델로는 문제점이 나타난다. 바로 과거의 정보들을 미래의 정보로 끌고오는 상황이기에, 역설적으로 더 오래된(멀리있는) 정보일수록 살아남기 힘들다는 것이다. 이처럼 <span class="custom_underline">**RNN은 이처럼 `short-term dependencies`는 잘 잡지만, `Long-term dependencies`는 잡기 어렵다는 치명적 단점이 존재한다.**</span>

RNN은 과거의 $h$들을 고려하는 중첩된 구조인데, 식으로 표현하자면 다음과 같다.
$\$
h_1 = \phi(W^T h_0 + U^T x_1)
$$

$\$
h_2 = \phi(W^T \phi(W^T h_0 + U^T x_1) + U^T x_2)
$$

$\$
h_3 = \phi(W^T \phi(W^T \phi(W^T h_0 + U^T x_1) + U^T x_2) + U^T x_1)
$$

- $\phi$는 활성함수(activation function) 이다.
- 이와 같이 RNN은 여러 활성함수(input) 의 구조가 반복된다.

그렇다면, 활성화함수가 `sigmoid`라 한다면, 함수가 중첩될수록 점점 **기울기 소실**의 문제가 발생할테고, 만약 솰성화함수가 `ReLU`라면 **기울기 폭발** 문제가 발생하게 될것이다.

## **LSTM**

이러한 단점들을 없애기 위하여 나온 모델이 `Long Short Term Memory (LSTM)`이다.

![LSTM-model](https://mblogthumb-phinf.pstatic.net/MjAxNzExMThfNDEg/MDAxNTEwOTg1MDQ3MDMw.wwcYXAe5Ey8vgpjkgMsXGGsLyzsMYtMFTbrbkqL_2pog.nz961nq3XHPXZ8-9jGJxqs_J9EJ4FGWtQqu8DBfg8c0g.JPEG.chiyoonzzang/RNN.jpeg?type=w800)

**LSTM의 핵심은 4개의 상호작용 layer가 들어 있다는 점이다.**

복잡해 보이지만 생각보다 살펴보면 조금은 친근해질 수 있다.

![LSTM-sign](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile5.uf.tistory.com%2Fimage%2F993A93495ACB86A02FFAA8)

위 그림에서 각 선(line)은 한 노드의 output을 다른 노드의 input으로 vector 전체를 보내는 흐름을 나타낸다. 분홍색 동그라미는 vector 합과 같은 pointwise operation을 나타낸다. 노란색 박스는 학습된 neural network layer다. 합쳐지는 선은 concatenation을 의미하고, 갈라지는 선은 정보를 복사해서 다른 쪽으로 보내는 fork를 의미한다.

### **Cell state**

**Cell state**가 LSTM의 핵심이라 할 수 있다.

Cell state는 컨베이어 벨트와 같이, 작은 linear interaction만을 적용시켜 전체 체인을 계속 구동시킨다. 정보가 바뀌지 않고 그대로 흐르게만 할 수도, 혹은 다른 `Gate`를 통해 정보 제어하여 흘려보낼 수도 있다.

자세한 내용은 [링크](https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr) 를 클릭하여 알아보도록 하자. 각 게이트와 구조의 흐름을 굉장히 잘 설명해놓은 블로그이다.

## **GRU**

기존의 RSTM의 복잡한 구조 때문에, 조금 더 단순한 구조로 제안된 모델이다. `Gated Recurrent Unit (GRU)`의 약자로, **게이트가 3개 있던 LSTM과 달리 2개의 게이트(reset, update)만을 가진다. 또 cell state가 없으며, hidden state만을 가진다.**

![GRU-model](https://blogik.netlify.app/static/75d989c345d4d1e164c72c146c42f2f4/d2782/gru.png)

`Reset Gate` 가 기존의 `Forget Gate` 역할을 하고, `Input&Output Gate` 가 합쳐져 Update Gate 역할을 한다고 볼 수 있다.

파라미터 개수가 LSTM보다 적음에도 불구하고 비슷한 작용을 하므로, 대체로 일반화 성능이 좋은 편이다.

그러나 최근에는 LSTM과 GRU 모두 Transformer가 나오면서 대체되고 있는 추세다.

---

## **참고**
- [욕심많은 알파카](https://blogik.netlify.app/BoostCamp/U_stage/19_rnn_basic/)
- [개발새발로그](https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr)