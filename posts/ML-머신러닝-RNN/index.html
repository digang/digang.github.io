 <!DOCTYPE html><html lang="en" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } }, tex2jax: { inlineMath: [ ['$', '$'] ], displayMath: [ ['$$', '$$'] ], processEscapes: true, } }); MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) { alert("Math Processing Error: "+message[1]); }); MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) { alert("Math Processing Error: "+message[1]); }); </script> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="[ML 머신러닝] RNN" /><meta property="og:locale" content="en" /><meta name="description" content="RNN" /><meta property="og:description" content="RNN" /><link rel="canonical" href="https://digang.github.io/posts/ML-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-RNN/" /><meta property="og:url" content="https://digang.github.io/posts/ML-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-RNN/" /><meta property="og:site_name" content="DIGANG’s BLOG" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-12-12T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="[ML 머신러닝] RNN" /><meta name="twitter:site" content="@digang" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-12-12T00:00:00+09:00","datePublished":"2021-12-12T00:00:00+09:00","description":"RNN","headline":"[ML 머신러닝] RNN","mainEntityOfPage":{"@type":"WebPage","@id":"https://digang.github.io/posts/ML-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-RNN/"},"url":"https://digang.github.io/posts/ML-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-RNN/"}</script><title>[ML 머신러닝] RNN | DIGANG's BLOG</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="DIGANG's BLOG"><meta name="application-name" content="DIGANG's BLOG"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/salsun.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">DIGANG's BLOG</a></div><div class="site-subtitle font-italic"></div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/digang" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/digang" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['tk119994','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>[ML 머신러닝] RNN</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>[ML 머신러닝] RNN</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/digang">digang(JeongYong)</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2021-12-12 00:00:00 +0900" data-toggle="tooltip" data-placement="bottom" title="Sun, Dec 12, 2021, 12:00 AM +0900" >Dec 12, 2021</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1294 words"> <em>7 min</em> read</span></div></div></div><div class="post-content"><h1 id="rnn"><strong>RNN</strong></h1><hr /><h2 id="sequential-model"><strong>Sequential Model</strong> <a href="#sequential-model" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="시퀀스-데이터"><strong>시퀀스 데이터</strong> <a href="#시퀀스-데이터" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>순차적 데이터<li>사건의 발생 순서가 중요한 경우 ( 온도, 자연어, 소리, 주가.. 등)<li>순서를 바꾸거나 정보에 손실이 생길경우 데이터의 확률분포 또한 바뀌게 됨.</ul><h3 id="sequential-model-1"><strong>Sequential Model</strong> <a href="#sequential-model-1" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p>시퀀스 데이터를 처리하는데 어려운 것은, <span class="custom_underline"><strong>길이의 끝이 언제인지 모른다는 점</strong></span>이다. 때문에, <strong>입력의 차원 또한 알 수 없다.</strong></p><ul><li>이를 해결하는 방법으로, <strong>고정된 길이 ($\tau$)의 과거정보만을 확인</strong>하는 <code class="language-plaintext highlighter-rouge">Markov Model</code>이 있다. 극단적으로 간단히 만든 것이 바로 직전 시점 정보만을 고려하는 <code class="language-plaintext highlighter-rouge">AR(1) 모델</code>이다.<li>기존 <code class="language-plaintext highlighter-rouge">AR모델</code>을 보완한것이, 과거의 정보들을 ‘기억’하는 모델을 만들었는데 그것이 바로 <code class="language-plaintext highlighter-rouge">Latent Autoregressive Model</code>이다.</ul><p><img data-src="https://media.vlpt.us/images/hanlyang0522/post/34fcf2a4-1112-40b7-ab01-7b9f50f8ce56/image.png" alt="Latent" data-proofer-ignore></p><center>출처 : [https://velog.io/@hanlyang0522/DL-Basic-7%EA%B0%95-Sequential-Models-RNN] </center><p>이 모델은 hidden state인데, <strong>출력값이 입력값에 그 전까지 모든 시점정보들을 요약한 값을 고려</strong>하여 만들어진다.</p><h2 id="recurrent-neural-network"><strong>Recurrent Neural Network</strong> <a href="#recurrent-neural-network" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>맥락을 이해하고 처리하기 위해서는 이전의 결과가 다음 결과에 영향을 미칠 수 있어야 한다. 영향을 미칠 수 있어야 <code class="language-plaintext highlighter-rouge">Series</code>데이터 처리가 가능하다.</p><p><img data-src="https://miro.medium.com/max/1400/0*V5Q5gGhiDGurHd-z.png" alt="RNN-model" data-proofer-ignore></p><ul><li>$x_t$는 입력값 $h_t$는 출력값이다.<li>A는 뉴럴넷 덩어리 이다.<li>A의 결과는 다시 A로 들어가서 루프를 생성한다. 때문에, <strong>현재의 상태(state)가 다음 상태(state)에 영향을 미치게 된다.</strong></ul><p>저것을 풀어 설명한 그림이 오른쪽 그림이다.</p><p><span class="custom_underline"><strong>어찌되었든 핵심은 RNN의 상태(state)를 계산할때, 이전 상태(state)를 계산한다는 것이다.</strong></span></p><p>하지만 아직 이 모델로는 문제점이 나타난다. 바로 과거의 정보들을 미래의 정보로 끌고오는 상황이기에, 역설적으로 더 오래된(멀리있는) 정보일수록 살아남기 힘들다는 것이다. 이처럼 <span class="custom_underline"><strong>RNN은 이처럼 <code class="language-plaintext highlighter-rouge">short-term dependencies</code>는 잘 잡지만, <code class="language-plaintext highlighter-rouge">Long-term dependencies</code>는 잡기 어렵다는 치명적 단점이 존재한다.</strong></span></p><p>RNN은 과거의 $h$들을 고려하는 중첩된 구조인데, 식으로 표현하자면 다음과 같다. $$ h_1 = \phi(W^T h_0 + U^T x_1) $$</p><p>$$ h_2 = \phi(W^T \phi(W^T h_0 + U^T x_1) + U^T x_2) $$</p><p>$$ h_3 = \phi(W^T \phi(W^T \phi(W^T h_0 + U^T x_1) + U^T x_2) + U^T x_1) $$</p><ul><li>$\phi$는 활성함수(activation function) 이다.<li>이와 같이 RNN은 여러 활성함수(input) 의 구조가 반복된다.</ul><p>그렇다면, 활성화함수가 <code class="language-plaintext highlighter-rouge">sigmoid</code>라 한다면, 함수가 중첩될수록 점점 <strong>기울기 소실</strong>의 문제가 발생할테고, 만약 솰성화함수가 <code class="language-plaintext highlighter-rouge">ReLU</code>라면 <strong>기울기 폭발</strong> 문제가 발생하게 될것이다.</p><h2 id="lstm"><strong>LSTM</strong> <a href="#lstm" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>이러한 단점들을 없애기 위하여 나온 모델이 <code class="language-plaintext highlighter-rouge">Long Short Term Memory (LSTM)</code>이다.</p><p><img data-src="https://mblogthumb-phinf.pstatic.net/MjAxNzExMThfNDEg/MDAxNTEwOTg1MDQ3MDMw.wwcYXAe5Ey8vgpjkgMsXGGsLyzsMYtMFTbrbkqL_2pog.nz961nq3XHPXZ8-9jGJxqs_J9EJ4FGWtQqu8DBfg8c0g.JPEG.chiyoonzzang/RNN.jpeg?type=w800" alt="LSTM-model" data-proofer-ignore></p><p><strong>LSTM의 핵심은 4개의 상호작용 layer가 들어 있다는 점이다.</strong></p><p>복잡해 보이지만 생각보다 살펴보면 조금은 친근해질 수 있다.</p><p><img data-src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=http%3A%2F%2Fcfile5.uf.tistory.com%2Fimage%2F993A93495ACB86A02FFAA8" alt="LSTM-sign" data-proofer-ignore></p><p>위 그림에서 각 선(line)은 한 노드의 output을 다른 노드의 input으로 vector 전체를 보내는 흐름을 나타낸다. 분홍색 동그라미는 vector 합과 같은 pointwise operation을 나타낸다. 노란색 박스는 학습된 neural network layer다. 합쳐지는 선은 concatenation을 의미하고, 갈라지는 선은 정보를 복사해서 다른 쪽으로 보내는 fork를 의미한다.</p><h3 id="cell-state"><strong>Cell state</strong> <a href="#cell-state" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><strong>Cell state</strong>가 LSTM의 핵심이라 할 수 있다.</p><p>Cell state는 컨베이어 벨트와 같이, 작은 linear interaction만을 적용시켜 전체 체인을 계속 구동시킨다. 정보가 바뀌지 않고 그대로 흐르게만 할 수도, 혹은 다른 <code class="language-plaintext highlighter-rouge">Gate</code>를 통해 정보 제어하여 흘려보낼 수도 있다.</p><p>자세한 내용은 <a href="https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr">링크</a> 를 클릭하여 알아보도록 하자. 각 게이트와 구조의 흐름을 굉장히 잘 설명해놓은 블로그이다.</p><h2 id="gru"><strong>GRU</strong> <a href="#gru" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>기존의 RSTM의 복잡한 구조 때문에, 조금 더 단순한 구조로 제안된 모델이다. <code class="language-plaintext highlighter-rouge">Gated Recurrent Unit (GRU)</code>의 약자로, <strong>게이트가 3개 있던 LSTM과 달리 2개의 게이트(reset, update)만을 가진다. 또 cell state가 없으며, hidden state만을 가진다.</strong></p><p><img data-src="https://blogik.netlify.app/static/75d989c345d4d1e164c72c146c42f2f4/d2782/gru.png" alt="GRU-model" data-proofer-ignore></p><p><code class="language-plaintext highlighter-rouge">Reset Gate</code> 가 기존의 <code class="language-plaintext highlighter-rouge">Forget Gate</code> 역할을 하고, <code class="language-plaintext highlighter-rouge">Input&amp;Output Gate</code> 가 합쳐져 Update Gate 역할을 한다고 볼 수 있다.</p><p>파라미터 개수가 LSTM보다 적음에도 불구하고 비슷한 작용을 하므로, 대체로 일반화 성능이 좋은 편이다.</p><p>그러나 최근에는 LSTM과 GRU 모두 Transformer가 나오면서 대체되고 있는 추세다.</p><hr /><h2 id="참고"><strong>참고</strong> <a href="#참고" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li><a href="https://blogik.netlify.app/BoostCamp/U_stage/19_rnn_basic/">욕심많은 알파카</a><li><a href="https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr">개발새발로그</a></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/ml/'>ML</a>, <a href='/categories/rnn/'>RNN</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/" class="post-tag no-text-decoration" >머신러닝</a> <a href="/tags/rnn/" class="post-tag no-text-decoration" >RNN</a> <a href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/" class="post-tag no-text-decoration" >딥러닝</a> <a href="/tags/ml/" class="post-tag no-text-decoration" >ML</a> <a href="/tags/deeplearning/" class="post-tag no-text-decoration" >Deeplearning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=[ML 머신러닝] RNN - DIGANG's BLOG&url=https://digang.github.io/posts/ML-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-RNN/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=[ML 머신러닝] RNN - DIGANG's BLOG&u=https://digang.github.io/posts/ML-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-RNN/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=[ML 머신러닝] RNN - DIGANG's BLOG&url=https://digang.github.io/posts/ML-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-RNN/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/ML-GAN-GAN_4/">[ML 머신러닝] GAN - 정복하기 (4) GAN의 종류 - 2</a><li><a href="/posts/ML-GAN-GAN_2/">[ML 머신러닝] GAN - 정복하기 (2)</a><li><a href="/posts/ML-Modern-CNN/">[ML] Modern CNN</a><li><a href="/posts/%EB%B0%B1%EC%A4%80-%ED%8C%8C%EC%9D%B4%ED%94%84-%EC%98%AE%EA%B8%B0%EA%B8%B01/">[백준 17070] 파이프 옮기기1 - python</a><li><a href="/posts/%EC%97%AD%EC%A0%84%ED%8C%8C%EC%88%9C%EC%A0%84%ED%8C%8C/">[ML] 선형모델과 역전파</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/">머신러닝</a> <a class="post-tag" href="/tags/ml/">ml</a> <a class="post-tag" href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a> <a class="post-tag" href="/tags/entropy/">entropy</a> <a class="post-tag" href="/tags/%EB%B0%B1%EC%A4%80/">백준</a> <a class="post-tag" href="/tags/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a> <a class="post-tag" href="/tags/deeplearning/">Deeplearning</a> <a class="post-tag" href="/tags/ml/">ML</a> <a class="post-tag" href="/tags/%EA%B0%84/">간</a> <a class="post-tag" href="/tags/%EA%B0%A0/">갠</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95/"><div class="card-body"> <em class="timeago small" date="2021-11-01 00:00:00 +0900" >Nov 1, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[ML] 경사하강법</h3><div class="text-muted small"><p> 선형회귀 선형회귀 : 이루어진 데이터들 속에서 결곽값을 잘 내는 모델을 찾는 것 경사하강법 sklearn 라이브러리 회귀분석 방법도 있다. 링크 우리가 알아볼 것은 경사하강법이다!&amp;lt;/br&amp;gt; 경사하강법으로 선형회귀 계수 구하기 선형회귀의 목적식 : ${\parallel y...</p></div></div></a></div><div class="card"> <a href="/posts/%EC%97%AD%EC%A0%84%ED%8C%8C%EC%88%9C%EC%A0%84%ED%8C%8C/"><div class="card-body"> <em class="timeago small" date="2021-11-01 00:00:00 +0900" >Nov 1, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[ML] 선형모델과 역전파</h3><div class="text-muted small"><p> 딥러닝의 학습방법 1. 선형모델 데이터를 선형모델로 해석하여 $y$값과 선형모델 예측값 $\hat{y}$의 차이의 $L_2-norm$의 기댓값을 최소화하는 $\beta$를 찾는것이였다. $${min \parallel y- \hat{y} \parallel}_2$$ 그러나 선형 모델은 단순한 선형모델을 푸는데 사용할 수 있지만, 분류(Classif...</p></div></div></a></div><div class="card"> <a href="/posts/ML-Math_-AI-%ED%99%95%EB%A5%A0%EB%A1%A0/"><div class="card-body"> <em class="timeago small" date="2021-12-10 00:00:00 +0900" >Dec 10, 2021</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[ML] Math_AI 확률론</h3><div class="text-muted small"><p> [ML] 확률론 딥러닝에서 확률론에 대해 공부해야 하는 이유 기계학습에서 손실함수의 작동원리는 데이터 공간을 통게학적으로 해석해서 유도함. 예측이 틀릴 위험(risk)을 최소화하도록 데이터를 학습하는 원리는 통계적 기계학습의 기본원리 회귀분석에서 손실함수로 사용되는 $L_2$-norm 은 예측오차의 분산을 가장 최소화 하는...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/ML-Modern-CNN/" class="btn btn-outline-primary" prompt="Older"><p>[ML] Modern CNN</p></a> <a href="/posts/ML-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%8B%9C%ED%80%80%EC%85%9C/" class="btn btn-outline-primary" prompt="Newer"><p>[ML 머신러닝] Transformer 모델 기초</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/digang">digang(JeongYong)</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/">머신러닝</a> <a class="post-tag" href="/tags/ml/">ml</a> <a class="post-tag" href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a> <a class="post-tag" href="/tags/entropy/">entropy</a> <a class="post-tag" href="/tags/%EB%B0%B1%EC%A4%80/">백준</a> <a class="post-tag" href="/tags/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/">알고리즘</a> <a class="post-tag" href="/tags/deeplearning/">Deeplearning</a> <a class="post-tag" href="/tags/ml/">ML</a> <a class="post-tag" href="/tags/%EA%B0%84/">간</a> <a class="post-tag" href="/tags/%EA%B0%A0/">갠</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
